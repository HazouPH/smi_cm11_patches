From 828b43720c454e8132bdc6de874004adbbfa3f3d Mon Sep 17 00:00:00 2001
From: Joakim Landberg <joakim.landberg@intel.com>
Date: Thu, 19 Jun 2014 10:45:39 +0200
Subject: [PATCH 15/17] Align MCG with ABT branch

BZ: 171109

Aligns MCG to ABT branch after code review
fixes of the first six Intel patches on ABT branch.

Change-Id: I5c1b8264596b2b516d65c49fb83aab1a2df6a449
Category: aosp improvement
Domain: AOSP-Others
Origin: internal
Upstream-Candidate: yes
Signed-off-by: Joakim Landberg <joakim.landberg@intel.com>
---
 Android.mk                                  |    1 +
 src/core/SkBitmapProcShader.cpp             |    3 +-
 src/core/SkBitmapProcState.cpp              |  121 --
 src/core/SkBitmapProcState.h                |    7 +-
 src/core/SkBlitter_RGB16.cpp                |    8 +-
 src/opts/SkBitmapProcState_opts_SSE2.cpp    | 1712 +++++++++++++--------------
 src/opts/SkBitmapProcState_opts_SSE2.h      |   23 +-
 src/opts/SkBitmapProcState_opts_SSE2_asm.S  |  131 --
 src/opts/SkBitmapProcState_opts_SSSE3.cpp   |  249 ++--
 src/opts/SkBitmapProcState_opts_SSSE3.h     |    3 +
 src/opts/SkBitmapProcState_opts_SSSE3_asm.S |  130 ++
 src/opts/SkBlitRow_opts_SSE2.h              |   25 +-
 src/opts/opts_check_x86.cpp                 |    9 +-
 13 files changed, 1178 insertions(+), 1244 deletions(-)
 create mode 100644 src/opts/SkBitmapProcState_opts_SSSE3_asm.S

diff --git a/Android.mk b/Android.mk
index a63c79e..c90bfc4 100644
--- a/Android.mk
+++ b/Android.mk
@@ -566,6 +566,7 @@ LOCAL_SRC_FILES += \
     src/opts/SkBitmapProcState_opts_SSE2.cpp \
     src/opts/SkBitmapProcState_opts_SSE2_asm.S \
     src/opts/SkBitmapProcState_opts_SSSE3.cpp \
+    src/opts/SkBitmapProcState_opts_SSSE3_asm.S \
     src/opts/SkBlitRect_opts_SSE2.cpp \
     src/opts/SkUtils_opts_SSE2.cpp \
     src/opts/SkXfermode_opts_none.cpp \
diff --git a/src/core/SkBitmapProcShader.cpp b/src/core/SkBitmapProcShader.cpp
index 917b251..a9abcec 100644
--- a/src/core/SkBitmapProcShader.cpp
+++ b/src/core/SkBitmapProcShader.cpp
@@ -196,8 +196,7 @@ void SkBitmapProcShader::shadeSpan(int x, int y, SkPMColor dstC[], int count) {
         return;
     }
 
-    uint32_t buffer1[BUF_MAX + TEST_BUFFER_EXTRA+ 16];
-    uint32_t* buffer = (uint32_t*)(((size_t)buffer1+ 0xF) &(~0xF));
+    uint32_t  __attribute__((aligned(16))) buffer[BUF_MAX + TEST_BUFFER_EXTRA];
 
     SkBitmapProcState::MatrixProc   mproc = state.getMatrixProc();
     SkBitmapProcState::SampleProc32 sproc = state.getSampleProc32();
diff --git a/src/core/SkBitmapProcState.cpp b/src/core/SkBitmapProcState.cpp
index 2450c63..0244637 100644
--- a/src/core/SkBitmapProcState.cpp
+++ b/src/core/SkBitmapProcState.cpp
@@ -34,47 +34,6 @@ extern void  Clamp_S32_Opaque_D32_filter_DX_shaderproc_neon(const SkBitmapProcSt
 #include "SkBitmapProcState_procs.h"
 
 ///////////////////////////////////////////////////////////////////////////////
-extern "C" void S32_Opaque_D32_filter_line_SSSE3_asm(uint32_t* row0,
-                                  uint32_t* row1,
-                                  SkFixed fx, unsigned subY,
-                                  uint32_t* colors, SkFixed dx,
-                                  int count);
-static void S32_Opaque_D32_filter_line(uint32_t* row0, uint32_t* row1,
-                                  SkFixed fx, unsigned subY,
-                                  uint32_t* colors, SkFixed dx,
-                                  int count)
-{
-    while (count--) {
-        unsigned subX = (((fx) >> 12) & 0xF);
-        unsigned x0 = (fx) >> 16;
-        Filter_32_opaque(subX, subY, row0[x0], row0[x0+1],
-                                  row1[x0], row1[x0+1], colors);
-        colors++;
-        fx += dx;
-    }
-}
-static SkFixed S32_Opaque_D32_filter_line_rewind(uint32_t* row0,
-                                           uint32_t* row1,
-                                           SkFixed fx, unsigned subY,
-                                           uint32_t* colors, SkFixed dx,
-                                           int count, SkFixed oneX,
-                                           int maxX)
-{
-    while (count--)
-    {
-        unsigned subX = (((fx) >> 12) & 0xF);
-        int x0 = (fx) >> 16;
-        if (x0 < 0) x0 = x0 + maxX;
-        int x1 = (fx + oneX) >> 16;
-        if (x1 > maxX) x1 = x1 -maxX;
-        Filter_32_opaque(subX, subY, row0[x0], row0[x1],
-                                  row1[x0], row1[x1], colors);
-        colors++;
-        fx += dx;
-    }
-    return fx;
-}
-
 
 // true iff the matrix contains, at most, scale and translate elements
 static bool matrix_only_scale_translate(const SkMatrix& m) {
@@ -1090,83 +1049,3 @@ int SkBitmapProcState::maxCountForBufferSize(size_t bufferSize) const {
 
     return size;
 }
-
-#define COUNT_NUMS_OF_STAGE(start, end, det)\
-    do { \
-       num = ((end) - (start))/(det)+1;\
-       if (num < rest )        \
-       {                       \
-           runs = num;         \
-           rest = rest - num;  \
-       } else {                \
-           runs = rest;        \
-           rest = 0;           \
-       }                       \
-    } while (0)
-
-void Repeate_S32_Opaque_D32_filter_DX_shaderproc_opt(const SkBitmapProcState& s,
-                                            int x, int y, uint32_t* colors,
-                                            int count) {
-
-    SkASSERT((s.fBitmap->width()) > 1);
-    SkASSERT(((s.fInvSx) > 0) && (s.fInvSx & 0xFFFF));
-    const unsigned maxX = s.fBitmap->width() - 1;
-    const SkFixed oneX = s.fFilterOneX;
-    const SkFixed dx = s.fInvSx;
-    SkFixed fx;
-    uint32_t* row0;
-    uint32_t* row1;
-    unsigned subY;
-    {
-        SkPoint pt;
-        s.fInvProc(s.fInvMatrix, ((float)(x)) + (0.5f),
-                   ((float)(y)) + (0.5f), &pt);
-        SkFixed fy = ((SkFixed)((pt.fY) * (1 << 16))) - (s.fFilterOneY >> 1);
-        const unsigned maxY = s.fBitmap->height() - 1;
-
-        subY =  ((((fy) & 0xFFFF) * ((maxY) + 1) >> 12) & 0xF);
-        int y0 = (((fy) & 0xFFFF) * ((maxY) + 1) >> 16);
-        int y1 = (((fy + s.fFilterOneY) & 0xFFFF) * ((maxY) + 1) >> 16);
-
-        const char* __restrict__ srcAddr = (const char*)s.fBitmap->getPixels();
-        unsigned rb = s.fBitmap->rowBytes();
-        row0 = (uint32_t*)(srcAddr + y0 * rb);
-        row1 = (uint32_t*)(srcAddr + y1 * rb);
-
-        fx = SkScalarToFixed(pt.fX) - (oneX >> 1);
-        SkFixed fmax = (maxX << 16);
-        SkFixed foneX = oneX *(maxX+1);
-        int num = 0;
-        int runs = 0;
-        int rest = count;
-        SkFixed ffx = (fx & 0xFFFF )* ( maxX+1 );
-        SkFixed fdx = (dx & 0xFFFF) * ( maxX+1 );
-        SkFixed ffx1 = ffx + foneX;
-        while (rest>0)
-        {
-            // normal case;
-            if (ffx >= 0 && ffx1 < fmax)
-            {
-                COUNT_NUMS_OF_STAGE(ffx1, fmax, fdx);
-                S32_Opaque_D32_filter_line_SSSE3_asm(row0, row1, ffx, subY,
-                                                colors, fdx, runs);
-                ffx = ffx + fdx * runs;
-                colors = colors + runs;
-                ffx1 = ffx + foneX;
-            }
-            // rare case
-            if (rest > 0 && ffx < fmax && ffx1 >= fmax) {
-                COUNT_NUMS_OF_STAGE(ffx, fmax, fdx);
-                ffx = S32_Opaque_D32_filter_line_rewind(row0, row1, ffx, subY,
-                                                colors, fdx, runs, foneX, maxX);
-                colors = colors + runs;
-                ffx1 = ffx + foneX;
-            }
-            if (ffx >= fmax){
-                // rewind ffx;
-                ffx = ffx - fmax;
-                ffx1 = ffx + foneX;
-            }
-        }
-    }
-}
diff --git a/src/core/SkBitmapProcState.h b/src/core/SkBitmapProcState.h
index f06c4e7..6d55e2d 100644
--- a/src/core/SkBitmapProcState.h
+++ b/src/core/SkBitmapProcState.h
@@ -223,10 +223,6 @@ void S32_opaque_D32_filter_DXDY(const SkBitmapProcState& s,
                                 const uint32_t xy[], int count, SkPMColor colors[]);
 void S32_alpha_D32_filter_DXDY(const SkBitmapProcState& s,
                                const uint32_t xy[], int count, SkPMColor colors[]);
-void S32_D16_filter_DX(const SkBitmapProcState& s, const uint32_t xy[],
-                              int count, uint16_t colors[]);
-void S32_opaque_D32_nofilter_DX(const SkBitmapProcState& s, const uint32_t xy[],
-                             int count, SkPMColor colors[]);
 void ClampX_ClampY_filter_scale(const SkBitmapProcState& s, uint32_t xy[],
                                 int count, int x, int y);
 void ClampX_ClampY_nofilter_scale(const SkBitmapProcState& s, uint32_t xy[],
@@ -242,6 +238,7 @@ void highQualityFilter32(const SkBitmapProcState &s, int x, int y,
                          SkPMColor *SK_RESTRICT colors, int count);
 void highQualityFilter16(const SkBitmapProcState &s, int x, int y,
                          uint16_t *SK_RESTRICT colors, int count);
-
+void S32_opaque_D32_nofilter_DX(const SkBitmapProcState& s, const uint32_t xy[],
+                             int count, SkPMColor colors[]);
 
 #endif
diff --git a/src/core/SkBlitter_RGB16.cpp b/src/core/SkBlitter_RGB16.cpp
index f1e54ea..73ecb68 100644
--- a/src/core/SkBlitter_RGB16.cpp
+++ b/src/core/SkBlitter_RGB16.cpp
@@ -24,7 +24,7 @@
     #define USE_BLACK_BLITTER
 #endif
 
-#ifdef USE_SSE2
+#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
 #include <emmintrin.h>
 #endif
 
@@ -351,7 +351,7 @@ void SkRGB16_Opaque_Blitter::blitAntiH(int x, int y,
     }
 }
 
-#ifdef USE_SSE2
+#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
 static unsigned int solid_pixels_masks[1024] = {
   0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0xFFFF0000,
   0x00000000, 0x00000000, 0x00000000, 0x0000FFFF, 0x00000000, 0x00000000, 0x00000000, 0xFFFFFFFF,
@@ -486,7 +486,7 @@ static unsigned int solid_pixels_masks[1024] = {
 // _mm_maskmoveu_si128(_mcolor, _mtemp, (char*)dst);
 #define solid_8_pixels(mask, dst, color)    \
     do {                                     \
-        if (mask != 0)  {                         \
+        if (mask != 0) {                         \
             __m128i _mtemp  = _mm_load_si128((__m128i*)(solid_pixels_masks + (mask << 2))); \
             __m128i _mcolor = _mm_set1_epi16((short)color);      \
             __m128i _mvalue = _mm_loadu_si128((__m128i*)dst);    \
@@ -510,7 +510,7 @@ static unsigned int solid_pixels_masks[1024] = {
         if (mask & 0x02) dst[6] = color;    \
         if (mask & 0x01) dst[7] = color;    \
     } while (0)
-#endif // #ifdef USE_SSE2
+#endif // #if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
 
 #define SK_BLITBWMASK_NAME                  SkRGB16_BlitBW
 #define SK_BLITBWMASK_ARGS                  , uint16_t color
diff --git a/src/opts/SkBitmapProcState_opts_SSE2.cpp b/src/opts/SkBitmapProcState_opts_SSE2.cpp
index 91a83a7..7407eb1 100644
--- a/src/opts/SkBitmapProcState_opts_SSE2.cpp
+++ b/src/opts/SkBitmapProcState_opts_SSE2.cpp
@@ -13,11 +13,17 @@
 #include "SkUtils.h"
 #include "SkBitmapProcState_filter.h"
 
-__attribute__((aligned(16)))
-uint32_t vf[4] = {0xF,0xf,0xf,0xf};
-uint32_t vmask2[4] = {0xff00ff00,0xff00ff00,0xff00ff00,0xff00ff00};
-unsigned short v256[8] = {256,256,256,256,256,256,256,256};
-uint32_t vmask[4] = {0x00ff00ff,0x00ff00ff,0x00ff00ff,0x00ff00ff};
+const uint32_t __attribute__((aligned(16))) cvf[4] = {0xF,0xf,0xf,0xf};
+const uint32_t __attribute__((aligned(16))) cvmask2[4] = {0xff00ff00,
+                                    0xff00ff00,0xff00ff00,0xff00ff00};
+const unsigned short __attribute__((aligned(16))) cv256[8] = {256,256,
+                                               256,256,256,256,256,256};
+const uint32_t __attribute__((aligned(16))) cvmask[4] = {0x00ff00ff,
+                                      0x00ff00ff,0x00ff00ff,0x00ff00ff};
+extern "C" void S32_opaque_D32_nofilter_DX_SSE2_asm(const uint32_t* xy,
+                                                    int count,
+                                                    const SkPMColor* srcAddr,
+                                                    uint32_t* colors);
 
 void S32_opaque_D32_filter_DX_SSE2(const SkBitmapProcState& s,
                                    const uint32_t* xy,
@@ -755,7 +761,7 @@ void S32_D16_filter_DX_SSE2(const SkBitmapProcState& s,
         // Extract low int and store.
         dstColor = _mm_cvtsi128_si32(sum);
 
-        // *colors++ = SkPixel32ToPixel16(dstColor);
+        //*colors++ = SkPixel32ToPixel16(dstColor);
         // below is much faster than the above. It's tested for Android benchmark--Softweg
         __m128i _m_temp1 = _mm_set1_epi32(dstColor);
         __m128i _m_temp2 = _mm_srli_epi32(_m_temp1, 3);
@@ -775,12 +781,6 @@ void S32_D16_filter_DX_SSE2(const SkBitmapProcState& s,
 
     } while (--count > 0);
 }
-
-extern "C" void S32_opaque_D32_nofilter_DX_SSE2_asm(const uint32_t* xy,
-                                                    int count,
-                                                    const SkPMColor* srcAddr,
-                                                    uint32_t* colors);
-
 void S32_opaque_D32_nofilter_DX_SSE2(const SkBitmapProcState& s,
                                      const uint32_t* xy,
                                      int count, uint32_t* colors) {
@@ -825,795 +825,792 @@ void S32_opaque_D32_filter_DXDY_SSE2(const SkBitmapProcState& s,
                                   const uint32_t* xy,
                                   int count, uint32_t* colors) {
 
-    SkASSERT(count > 0 && colors != NULL);
-    SkASSERT(s.fDoFilter);
-    SkASSERT(s.fBitmap->config() == SkBitmap::kARGB_8888_Config);
-    SkASSERT(s.fAlphaScale == 256);
-    uint32_t data;
-    unsigned y0, y1, x0, x1, subX, subY;
-    const SkPMColor *row0, *row1;
-
-    const char* srcAddr = static_cast<const char*>(s.fBitmap->getPixels());
-    unsigned rb = s.fBitmap->rowBytes();
-    if (count >= 4) {
-        while (((size_t)xy & 0x0F) != 0)
-        {
-            data = *xy++;
-            y0 = data >> 14;
-            y1 = data & 0x3FFF;
-            subY = y0 & 0xF;
-            y0 >>= 4;
-
-            data = *xy++;
-            x0 = data >> 14;
-            x1 = data & 0x3FFF;
-            subX = x0 & 0xF;
-            x0 >>= 4;
-
-            row0 = (const SkPMColor*)(srcAddr + y0 * rb);
-            row1 = (const SkPMColor*)(srcAddr + y1 * rb);
-
-            Filter_32_opaque(subX, subY,
+   SkASSERT(count > 0 && colors != NULL);
+   SkASSERT(s.fDoFilter);
+   SkASSERT(s.fBitmap->config() == SkBitmap::kARGB_8888_Config);
+   SkASSERT(s.fAlphaScale == 256);
+   uint32_t data;
+   unsigned y0, y1, x0, x1, subX, subY;
+   const SkPMColor *row0, *row1;
+
+   const char* srcAddr = static_cast<const char*>(s.fBitmap->getPixels());
+   unsigned rb = s.fBitmap->rowBytes();
+   if (count >= 4) {
+       while (((size_t)xy & 0x0F) != 0)
+       {
+           data = *xy++;
+           y0 = data >> 14;
+           y1 = data & 0x3FFF;
+           subY = y0 & 0xF;
+           y0 >>= 4;
+
+           data = *xy++;
+           x0 = data >> 14;
+           x1 = data & 0x3FFF;
+           subX = x0 & 0xF;
+           x0 >>= 4;
+
+           row0 = (const SkPMColor*)(srcAddr + y0 * rb);
+           row1 = (const SkPMColor*)(srcAddr + y1 * rb);
+
+           Filter_32_opaque(subX, subY,
                        (row0[x0]),
                        (row0[x1]),
                        (row1[x0]),
                        (row1[x1]),
                        colors);
-            colors += 1;
-            --count;
-        }
-        __m128i vf = _mm_set1_epi32(0xF);
-        __m128i vmask = _mm_set1_epi32(gMask_00FF00FF);
-        __m128i vmask2 = _mm_set1_epi32(0xff00ff00);
-        __m128i v256 = _mm_set1_epi16(256);
-        __m128i *d = reinterpret_cast<__m128i*>(colors);
-        while (count >= 4) {
-            __m128i vy_d = _mm_load_si128((__m128i*)xy);
-            __m128i vx_d = _mm_load_si128((__m128i*)(xy+4));
-            __m128i vy = (__m128i)_mm_shuffle_ps((__m128)vy_d,(__m128)vx_d,0x88);
-            __m128i vx = (__m128i)_mm_shuffle_ps((__m128)vy_d,(__m128)vx_d,0xdd);
-
-            uint32_t XY = *xy++;
-            const uint32_t* row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
-            const uint32_t* row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
-
-            uint32_t XX = *xy++;    // x0:14 | 4 | x1:14
-            unsigned x0 = XX >> 18;
-            unsigned x1 = XX & 0x3FFF;
-
-            __m128i a00 = _mm_cvtsi32_si128(row0[x0]);
-            __m128i a01 = _mm_cvtsi32_si128(row0[x1]);
-            __m128i a10 = _mm_cvtsi32_si128(row1[x0]);
-            __m128i a11 = _mm_cvtsi32_si128(row1[x1]);
-
-            XY = *xy++;
-            row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
-            row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
-
-            XX = *xy++;    // x0:14 | 4 | x1:14
-            x0 = XX >> 18;
-            x1 = XX & 0x3FFF;
-            a00 = _mm_unpacklo_epi32(a00,_mm_cvtsi32_si128(row0[x0]));
-            a01 = _mm_unpacklo_epi32(a01,_mm_cvtsi32_si128(row0[x1]));
-            a10 = _mm_unpacklo_epi32(a10,_mm_cvtsi32_si128(row1[x0]));
-            a11 = _mm_unpacklo_epi32(a11,_mm_cvtsi32_si128(row1[x1]));
-
-            XY = *xy++;
-            row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
-            row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
-
-            XX = *xy++;    // x0:14 | 4 | x1:14
-            x0 = XX >> 18;
-            x1 = XX & 0x3FFF;
-            __m128i a00_d = _mm_cvtsi32_si128(row0[x0]);
-            __m128i a01_d = _mm_cvtsi32_si128(row0[x1]);
-            __m128i a10_d = _mm_cvtsi32_si128(row1[x0]);
-            __m128i a11_d = _mm_cvtsi32_si128(row1[x1]);
-
-            XY = *xy++;
-            row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
-            row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
-
-            XX = *xy++;    // x0:14 | 4 | x1:14
-            x0 = XX >> 18;
-            x1 = XX & 0x3FFF;
-            a00_d = _mm_unpacklo_epi32(a00_d,_mm_cvtsi32_si128(row0[x0]));
-            a01_d = _mm_unpacklo_epi32(a01_d,_mm_cvtsi32_si128(row0[x1]));
-            a10_d = _mm_unpacklo_epi32(a10_d,_mm_cvtsi32_si128(row1[x0]));
-            a11_d = _mm_unpacklo_epi32(a11_d,_mm_cvtsi32_si128(row1[x1]));
-
-            vy = _mm_srli_epi32(vy,14);
-            vy = _mm_and_si128(vy,vf);
-
-            vx = _mm_srli_epi32(vx,14);
-            vx = _mm_and_si128(vx,vf);
-
-            a00 = _mm_unpacklo_epi64(a00,a00_d);
-            a01 = _mm_unpacklo_epi64(a01,a01_d);
-            a10 = _mm_unpacklo_epi64(a10,a10_d);
-            a11 = _mm_unpacklo_epi64(a11,a11_d);
-
-            vy = _mm_shufflelo_epi16(vy,0xa0);
-            vy = _mm_shufflehi_epi16(vy,0xa0);
-            vx = _mm_shufflelo_epi16(vx,0xa0);
-            vx = _mm_shufflehi_epi16(vx,0xa0);
-
-            // unsigned xy = x * y;
-            __m128i vxy = _mm_mullo_epi16(vx,vy);
-            __m128i v16y = _mm_slli_epi16(vy,4);
-            __m128i v16x = _mm_slli_epi16(vx,4);
-            // unsigned scale = 256 - 16*y - 16*x + xy;
-            __m128i vscale = _mm_add_epi16(v256,vxy);
-            vscale = _mm_sub_epi16(vscale,v16y);
-            vscale = _mm_sub_epi16(vscale,v16x);
-
-            // uint32_t lo = (a00 & mask) * scale;
-            __m128i vlo = _mm_and_si128(a00,vmask);
-            vlo = _mm_mullo_epi16(vlo, vscale);
-
-            // uint32_t hi = ((a00 >> 8) & mask) * scale;
-            __m128i vhi = _mm_srli_epi32(a00,8);
-            vhi = _mm_and_si128(vhi,vmask);
-            vhi = _mm_mullo_epi16(vhi, vscale);
-            // scale = 16*x-xy;
-            vscale = _mm_sub_epi16(v16x,vxy);
-
-            // lo += (a01 & mask) * scale;
-            __m128i vlo2 = _mm_and_si128(a01,vmask);
-            vlo2 = _mm_mullo_epi16(vlo2, vscale);
-            vlo = _mm_add_epi16(vlo,vlo2);
-
-            // hi += ((a01 >> 8) & mask) * scale;
-            __m128i vhi2 = _mm_srli_epi32(a01,8);
-            vhi2 = _mm_and_si128(vhi2,vmask);
-            vhi2 = _mm_mullo_epi16(vhi2, vscale);
-            vhi = _mm_add_epi16(vhi,vhi2);
-
-            // scale = 16*y - xy;
-            vscale = _mm_sub_epi16(v16y,vxy);
-
-            // lo += (a10 & mask) * scale;
-            vlo2 = _mm_and_si128(a10,vmask);
-            vlo2 = _mm_mullo_epi16(vlo2, vscale);
-            vlo = _mm_add_epi16(vlo,vlo2);
-
-            // hi += ((a10 >> 8) & mask) * scale;
-            vhi2 = _mm_srli_epi32(a10,8);
-            vhi2 = _mm_and_si128(vhi2,vmask);
-            vhi2 = _mm_mullo_epi16(vhi2, vscale);
-            vhi = _mm_add_epi16(vhi,vhi2);
-
-            // lo += (a11 & mask) * xy;
-            vlo2 = _mm_and_si128(a11,vmask);
-            vlo2 = _mm_mullo_epi16(vlo2, vxy);
-            vlo = _mm_add_epi16(vlo,vlo2);
-
-            // hi += ((a11 >> 8) & mask) * xy;
-            vhi2 = _mm_srli_epi32(a11,8);
-            vhi2 = _mm_and_si128(vhi2,vmask);
-            vhi2 = _mm_mullo_epi16(vhi2, vxy);
-            vhi = _mm_add_epi16(vhi,vhi2);
-
-            // *dstColor = ((lo >> 8) & mask) | (hi & ~mask);
-            vlo = _mm_srli_epi32(vlo,8);
-            vlo = _mm_and_si128(vlo,vmask);
-            vhi = _mm_and_si128(vhi,vmask2);
-
-            _mm_storeu_si128(d,_mm_or_si128(vlo,vhi));
-            d++;
-            count -= 4;
-        }
-    colors = reinterpret_cast<SkPMColor*>(d);
-    }
-    while (count > 0)
-    {
-        data = *xy++;
-        y0 = data >> 14;
-        y1 = data & 0x3FFF;
-        subY = y0 & 0xF;
-        y0 >>= 4;
-
-        data = *xy++;
-        x0 = data >> 14;
-        x1 = data & 0x3FFF;
-        subX = x0 & 0xF;
-        x0 >>= 4;
-
-        row0 = (const SkPMColor*)(srcAddr + y0 * rb);
-        row1 = (const SkPMColor*)(srcAddr + y1 * rb);
-
-        Filter_32_opaque(subX, subY,
+           colors += 1;
+           --count;
+       }
+       __m128i vf = _mm_set1_epi32(0xF);
+       __m128i vmask = _mm_set1_epi32(gMask_00FF00FF);
+       __m128i vmask2 = _mm_set1_epi32(0xff00ff00);
+       __m128i v256 = _mm_set1_epi16(256);
+       __m128i *d = reinterpret_cast<__m128i*>(colors);
+       while (count >= 4) {
+           __m128i vy_d = _mm_load_si128((__m128i*)xy);
+           __m128i vx_d = _mm_load_si128((__m128i*)(xy+4));
+           __m128i vy = (__m128i)_mm_shuffle_ps((__m128)vy_d,(__m128)vx_d,0x88);
+           __m128i vx = (__m128i)_mm_shuffle_ps((__m128)vy_d,(__m128)vx_d,0xdd);
+
+           uint32_t XY = *xy++;
+           const uint32_t* row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
+           const uint32_t* row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
+
+           uint32_t XX = *xy++;    // x0:14 | 4 | x1:14
+           unsigned x0 = XX >> 18;
+           unsigned x1 = XX & 0x3FFF;
+
+           __m128i a00 = _mm_cvtsi32_si128(row0[x0]);
+           __m128i a01 = _mm_cvtsi32_si128(row0[x1]);
+           __m128i a10 = _mm_cvtsi32_si128(row1[x0]);
+           __m128i a11 = _mm_cvtsi32_si128(row1[x1]);
+
+           XY = *xy++;
+           row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
+           row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
+
+           XX = *xy++;    // x0:14 | 4 | x1:14
+           x0 = XX >> 18;
+           x1 = XX & 0x3FFF;
+           a00 = _mm_unpacklo_epi32(a00,_mm_cvtsi32_si128(row0[x0]));
+           a01 = _mm_unpacklo_epi32(a01,_mm_cvtsi32_si128(row0[x1]));
+           a10 = _mm_unpacklo_epi32(a10,_mm_cvtsi32_si128(row1[x0]));
+           a11 = _mm_unpacklo_epi32(a11,_mm_cvtsi32_si128(row1[x1]));
+
+           XY = *xy++;
+           row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
+           row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
+
+           XX = *xy++;    // x0:14 | 4 | x1:14
+           x0 = XX >> 18;
+           x1 = XX & 0x3FFF;
+           __m128i a00_d = _mm_cvtsi32_si128(row0[x0]);
+           __m128i a01_d = _mm_cvtsi32_si128(row0[x1]);
+           __m128i a10_d = _mm_cvtsi32_si128(row1[x0]);
+           __m128i a11_d = _mm_cvtsi32_si128(row1[x1]);
+
+           XY = *xy++;
+           row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
+           row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
+
+           XX = *xy++;    // x0:14 | 4 | x1:14
+           x0 = XX >> 18;
+           x1 = XX & 0x3FFF;
+           a00_d = _mm_unpacklo_epi32(a00_d,_mm_cvtsi32_si128(row0[x0]));
+           a01_d = _mm_unpacklo_epi32(a01_d,_mm_cvtsi32_si128(row0[x1]));
+           a10_d = _mm_unpacklo_epi32(a10_d,_mm_cvtsi32_si128(row1[x0]));
+           a11_d = _mm_unpacklo_epi32(a11_d,_mm_cvtsi32_si128(row1[x1]));
+
+           vy = _mm_srli_epi32(vy,14);
+           vy = _mm_and_si128(vy,vf);
+
+           vx = _mm_srli_epi32(vx,14);
+           vx = _mm_and_si128(vx,vf);
+
+           a00 = _mm_unpacklo_epi64(a00,a00_d);
+           a01 = _mm_unpacklo_epi64(a01,a01_d);
+           a10 = _mm_unpacklo_epi64(a10,a10_d);
+           a11 = _mm_unpacklo_epi64(a11,a11_d);
+
+           vy = _mm_shufflelo_epi16(vy,0xa0);
+           vy = _mm_shufflehi_epi16(vy,0xa0);
+           vx = _mm_shufflelo_epi16(vx,0xa0);
+           vx = _mm_shufflehi_epi16(vx,0xa0);
+
+           // unsigned xy = x * y;
+           __m128i vxy = _mm_mullo_epi16(vx,vy);
+           __m128i v16y = _mm_slli_epi16(vy,4);
+           __m128i v16x = _mm_slli_epi16(vx,4);
+           // unsigned scale = 256 - 16*y - 16*x + xy;
+           __m128i vscale = _mm_add_epi16(v256,vxy);
+           vscale = _mm_sub_epi16(vscale,v16y);
+           vscale = _mm_sub_epi16(vscale,v16x);
+
+           // uint32_t lo = (a00 & mask) * scale;
+           __m128i vlo = _mm_and_si128(a00,vmask);
+           vlo = _mm_mullo_epi16(vlo, vscale);
+
+           // uint32_t hi = ((a00 >> 8) & mask) * scale;
+           __m128i vhi = _mm_srli_epi32(a00,8);
+           vhi = _mm_and_si128(vhi,vmask);
+           vhi = _mm_mullo_epi16(vhi, vscale);
+           // scale = 16*x-xy;
+           vscale = _mm_sub_epi16(v16x,vxy);
+
+           // lo += (a01 & mask) * scale;
+           __m128i vlo2 = _mm_and_si128(a01,vmask);
+           vlo2 = _mm_mullo_epi16(vlo2, vscale);
+           vlo = _mm_add_epi16(vlo,vlo2);
+
+           // hi += ((a01 >> 8) & mask) * scale;
+           __m128i vhi2 = _mm_srli_epi32(a01,8);
+           vhi2 = _mm_and_si128(vhi2,vmask);
+           vhi2 = _mm_mullo_epi16(vhi2, vscale);
+           vhi = _mm_add_epi16(vhi,vhi2);
+
+           // scale = 16*y - xy;
+           vscale = _mm_sub_epi16(v16y,vxy);
+
+           // lo += (a10 & mask) * scale;
+           vlo2 = _mm_and_si128(a10,vmask);
+           vlo2 = _mm_mullo_epi16(vlo2, vscale);
+           vlo = _mm_add_epi16(vlo,vlo2);
+
+           // hi += ((a10 >> 8) & mask) * scale;
+           vhi2 = _mm_srli_epi32(a10,8);
+           vhi2 = _mm_and_si128(vhi2,vmask);
+           vhi2 = _mm_mullo_epi16(vhi2, vscale);
+           vhi = _mm_add_epi16(vhi,vhi2);
+
+           // lo += (a11 & mask) * xy;
+           vlo2 = _mm_and_si128(a11,vmask);
+           vlo2 = _mm_mullo_epi16(vlo2, vxy);
+           vlo = _mm_add_epi16(vlo,vlo2);
+
+           // hi += ((a11 >> 8) & mask) * xy;
+           vhi2 = _mm_srli_epi32(a11,8);
+           vhi2 = _mm_and_si128(vhi2,vmask);
+           vhi2 = _mm_mullo_epi16(vhi2, vxy);
+           vhi = _mm_add_epi16(vhi,vhi2);
+
+           // *dstColor = ((lo >> 8) & mask) | (hi & ~mask);
+           vlo = _mm_srli_epi32(vlo,8);
+           vlo = _mm_and_si128(vlo,vmask);
+           vhi = _mm_and_si128(vhi,vmask2);
+
+           _mm_storeu_si128(d,_mm_or_si128(vlo,vhi));
+           d++;
+           count -= 4;
+       }
+       colors = reinterpret_cast<SkPMColor*>(d);
+   }
+   while (count > 0)
+   {
+       data = *xy++;
+       y0 = data >> 14;
+       y1 = data & 0x3FFF;
+       subY = y0 & 0xF;
+       y0 >>= 4;
+
+       data = *xy++;
+       x0 = data >> 14;
+       x1 = data & 0x3FFF;
+       subX = x0 & 0xF;
+       x0 >>= 4;
+
+       row0 = (const SkPMColor*)(srcAddr + y0 * rb);
+       row1 = (const SkPMColor*)(srcAddr + y1 * rb);
+
+       Filter_32_opaque(subX, subY,
                    (row0[x0]),
                    (row0[x1]),
                    (row1[x0]),
                    (row1[x1]),
                    colors);
-        colors += 1;
-        count --;
-   }
-
+       colors += 1;
+       count --;
+  }
 }
-
 void S32_opaque_D32_filter_DXDY_SSE2_asm(const SkBitmapProcState& s,
-        const uint32_t* xy, int count, uint32_t* colors) {
-    const char* srcAddr = static_cast<const char*>(s.fBitmap->getPixels());
-    unsigned rb = s.fBitmap->rowBytes();
-    uint32_t data;
-    unsigned y0, y1, x0, x1, subX, subY;
-    const SkPMColor *row0, *row1;
-    if (count >= 4) {
-        while (((size_t)xy & 0x0F) != 0)
-        {
-            data = *xy++;
-            y0 = data >> 14;
-            y1 = data & 0x3FFF;
-            subY = y0 & 0xF;
-            y0 >>= 4;
-
-            data = *xy++;
-            x0 = data >> 14;
-            x1 = data & 0x3FFF;
-            subX = x0 & 0xF;
-            x0 >>= 4;
-
-            row0 = (const SkPMColor*)(srcAddr + y0 * rb);
-            row1 = (const SkPMColor*)(srcAddr + y1 * rb);
-
-            Filter_32_opaque(subX, subY,
+                                  const uint32_t* xy,
+                                  int count, uint32_t* colors) {
+   const char* srcAddr = static_cast<const char*>(s.fBitmap->getPixels());
+   unsigned rb = s.fBitmap->rowBytes();
+   uint32_t data;
+   unsigned y0, y1, x0, x1, subX, subY;
+   const SkPMColor *row0, *row1;
+   if (count >= 4) {
+       while (((size_t)xy & 0x0F) != 0) {
+           data = *xy++;
+           y0 = data >> 14;
+           y1 = data & 0x3FFF;
+           subY = y0 & 0xF;
+           y0 >>= 4;
+
+           data = *xy++;
+           x0 = data >> 14;
+           x1 = data & 0x3FFF;
+           subX = x0 & 0xF;
+           x0 >>= 4;
+
+           row0 = (const SkPMColor*)(srcAddr + y0 * rb);
+           row1 = (const SkPMColor*)(srcAddr + y1 * rb);
+
+           Filter_32_opaque(subX, subY,
                        (row0[x0]),
                        (row0[x1]),
                        (row1[x0]),
                        (row1[x1]),
                        colors);
-            colors += 1;
-            --count;
-        }
-        if (count >= 4)
-        {
-            __attribute__((aligned(16)))
-            __m128i tmp5, tmp6, tmp8, tmp9, tmpa;
-            tmp5 = _mm_setzero_si128();
-            tmp6 = _mm_setzero_si128();
-            tmp8 = _mm_setzero_si128();
-            tmp9 = _mm_setzero_si128();
-            tmpa = _mm_setzero_si128();
-            // load 4 pixes in each run [D, C, B, A]
-            __asm__(
-            "1:\n"
-            // load pixel A
-            "mov    (%%edx),%%edi\n"  // *xy
-            "mov    %%edi,%%ecx\n"
-            "shr    $0x12,%%edi\n"    // *xy > 0x12
-            "and    $0x3fff,%%ecx\n"  // *xy & 0x3FFF
-            "imul   %[rb],%%edi\n"    // rb * y0
-            "imul   %[rb],%%ecx\n"    // rb * y1
-
-            "mov    0x4(%%edx),%%eax\n" // *(xy + 4)
-            "mov    %%eax,%%esi\n"
-            "shr    $0x12,%%esi\n"      // x0
-            "add    %[srcAddr],%%ecx\n" // row1.0 = srcAddr + rb * y1
-            "and    $0x3fff,%%eax\n"    // x1
-            "add    %[srcAddr],%%edi\n" // row0.0 = srcAddr + rb * y0
-
-            "movd   (%%ecx,%%esi,4),%%xmm6\n"    // A: a10
-            "movd   (%%ecx,%%eax,4),%%xmm7\n"    // A: a11
-            // load pixel B
-            "mov    0x8(%%edx),%%ecx\n"          // *(xy+8)
-            "movd   (%%edi,%%esi,4),%%xmm4\n"    // A:a00
-            "movd   (%%edi,%%eax,4),%%xmm5\n"    // A:a01
-            "mov    %%ecx,%%esi\n"
-            "and    $0x3fff,%%ecx\n"      // B:y1
-            "shr    $0x12,%%esi\n"        // B:y0
-            "imul   %[rb],%%ecx\n"        // rb * y1
-            "imul   %[rb],%%esi\n"        // rb * y0
-            "mov    0xc(%%edx),%%edi\n"
-            "mov    %%edi,%%eax\n"
-            "shr    $0x12,%%eax\n"        // B:x0
-            "add    %[srcAddr],%%ecx\n"   // B:row1.1
-            "and    $0x3fff,%%edi\n"      // B:x1
-            "add    %[srcAddr],%%esi\n"   // B:row0.1
-            "movd   (%%ecx,%%eax,4),%%xmm2\n"    // B:a10
-            "movd   (%%ecx,%%edi,4),%%xmm1\n"    // B:a11
-            // load pixel C
-            "mov    0x10(%%edx),%%ecx\n"
-            "movd   (%%esi,%%eax,4),%%xmm0\n"    // B:a00
-            "movd   (%%esi,%%edi,4),%%xmm3\n"    // B:a01
-
-            "mov    %%ecx,%%eax\n"
-            "shr    $0x12,%%eax\n"               // C:y0
-            "and    $0x3fff,%%ecx\n"             // C:y1
-            "imul   %[rb],%%eax\n"
-            "imul   %[rb],%%ecx\n"
-            // [0, Ba00, 0, Aa00]
-            "punpcklqdq %%xmm0,%%xmm4\n"
-            // [0, Ba01, 0, Aa01]
-            "punpcklqdq %%xmm3,%%xmm5\n"
-            "mov    0x14(%%edx),%%esi\n"
-            "mov    %%esi,%%edi\n"
-            "add    %[srcAddr],%%eax\n"          // C: row0
-            "add    %[srcAddr],%%ecx\n"          // C: row1
-            // [0, Ba11, 0, Aa11]
-            "punpcklqdq %%xmm1,%%xmm7\n"
-            // [0, Ba10, 0, Aa10]
-            "punpcklqdq %%xmm2,%%xmm6\n"
-            "and    $0x3fff,%%esi\n"
-            "shr    $0x12,%%edi\n"
-            // [0, 0, 0, Ca01]
-            "movd   0x0(%%eax,%%esi,4),%%xmm3\n"
-            // [0, 0, 0, Ca11]
-            "movd   (%%ecx,%%esi,4),%%xmm2\n"
-            // load pixel D
-            "mov    0x18(%%edx),%%esi\n"
-            // [0, 0, 0, Ca00]
-            "movd   0x0(%%eax,%%edi,4),%%xmm1\n"
-            "mov    %%esi,%%eax\n"
-            "shr    $0x12,%%esi\n"            // D:y0
-            "and    $0x3fff,%%eax\n"          // D:y1
-            // [0, 0, 0, Ca10]
-            "movd   (%%ecx,%%edi,4),%%xmm0\n"
-
-            "imul   %[rb],%%eax\n"            // D:rb * y0
-            "imul   %[rb],%%esi\n"            // D:rb * y1
-
-            "movdqa %%xmm2,%[tmp6]\n"         // save D:a11
-            "movdqa %%xmm0,%[tmp5]\n"         // save D:a10
-
-
-            "mov    0x1c(%%edx),%%ecx\n"
-            "mov    %%ecx,%%edi\n"
-            "add    %[srcAddr],%%esi\n"       // D:row0
-            "and    $0x3fff,%%ecx\n"          // D:x1
-            "shr    $0x12,%%edi\n"            // D:x0
-            "add    %[srcAddr],%%eax\n"       // D:row1
-
-            "movd   (%%esi,%%ecx,4),%%xmm2\n"    // D:a01
-            "movd   (%%esi,%%edi,4),%%xmm0\n"    // D:a00
-
-            // [0, Da01, 0, Ca01]
-            "punpcklqdq %%xmm2,%%xmm3\n"
-            // [0, Da00, 0, Ca00]
-            "punpcklqdq %%xmm0,%%xmm1\n"
-
-            "mov 0x0(%%eax,%%edi,4), %%esi\n"       // D:a10
-            "mov %%esi, %[tmp8]\n"                  // save D:a10
-
-            "movd   0x0(%%eax,%%ecx,4),%%xmm2\n"    // D:a11
-            // [Da00, Ca00, Ba00, Aa00]
-            "shufps $0x88,%%xmm1,%%xmm4\n"
-            "movdqa %[tmp6],%%xmm1\n"        // C:a11
-            // [0, Da11, 0, Ca11]
-            "punpcklqdq %%xmm2,%%xmm1\n"
-            // [Da11, Ca11, Ba11, Aa11]
-            "shufps $0x88,%%xmm1,%%xmm7\n"   // a11.3210
-
-            "movdqa  (%%edx),%%xmm1\n"        // vy_d
-
-            "movaps %%xmm1,%%xmm2\n"         // vy_d
-            "shufps $0xdd,0x10(%%edx),%%xmm1\n"    // vx
-            "shufps $0x88,0x10(%%edx),%%xmm2\n"    // vy
-
-            "psrld  $0xe,%%xmm1\n"        // vx>>14
-            // [Da01, Ca01, Ba01, Aa01]
-            "shufps $0x88,%%xmm3,%%xmm5\n"
-            "psrld  $0xe,%%xmm2\n"         // vy>>14
-
-            "add    $0x20,%%edx\n"        // xy+=8
-            "movdqa %[tmp5],%%xmm3\n"     // C:a10
-            "movhpd %[tmp8],%%xmm3\n"     // CD:a10
-
-            "pand   vf,%%xmm1\n"           // vx & vf
-            "pand   vf,%%xmm2\n"           // vy & vf
-            // [Da10, Ca10, Ba10, Aa10]
-            "shufps $0x88,%%xmm3,%%xmm6\n"
-
-            "pshuflw $0xa0,%%xmm1,%%xmm3\n"
-            "pshuflw $0xa0,%%xmm2,%%xmm0\n"
-            "pshufhw $0xa0,%%xmm3,%%xmm1\n"
-            "pshufhw $0xa0,%%xmm0,%%xmm2\n"
-
-            "movdqa %%xmm1,%%xmm3\n"
-            "pmullw %%xmm2,%%xmm3\n"         // vxy
-
-            "psllw  $0x4,%%xmm2\n"           // v16y
-            "movdqa v256,%%xmm0\n"
-            "psllw  $0x4,%%xmm1\n"           // v16x
-
-            "paddw  %%xmm3,%%xmm0\n"         // v256+vxy
-            "psubw  %%xmm2,%%xmm0\n"         // v256+vxy-v16y
-            "psubw  %%xmm3,%%xmm2\n"         // v16y-vxy    vscale 2
-
-            "movaps %%xmm4,%[tmp9]\n"        // a00
-            "psubw  %%xmm1,%%xmm0\n"         // v256+vxy-v16y-v16x   vscale0
-
-            "movaps %%xmm5,%[tmpa]\n"        // a01
-
-            "psubw  %%xmm3,%%xmm1\n"         // v16x-vxy   vscale 1
-            "pand   vmask,%%xmm4\n"          // a00 & vmask
-            "pand   vmask,%%xmm5\n"          // a01 & vmask
-
-            "pmullw %%xmm0,%%xmm4\n"         // a00.l*vscale0\n
-            "pmullw %%xmm1,%%xmm5\n"         // a01.l*vscale1\n
-
-            "paddw  %%xmm5,%%xmm4\n"         // a00.l+a01.l
-            "movaps %%xmm6,%%xmm5\n"         // a10
-            "pand   vmask,%%xmm5\n"          // a10.l
-            "psrld  $0x8,%%xmm6\n"           // a10.h
-            "pmullw %%xmm2,%%xmm5\n"         // a10.l*vscale2
-            "paddw  %%xmm5,%%xmm4\n"         // a00.l+a01.l+a10.l
-            "movaps %%xmm7,%%xmm5\n"         // a11
-            "pand   vmask,%%xmm5\n"          // a11.l
-            "psrld  $0x8,%%xmm7\n"           // a11.h
-            "pmullw %%xmm3,%%xmm5\n"         // a11.l*vxy
-            "paddw  %%xmm5,%%xmm4\n"         // a00.l+a01.l+a10.l+a11.l
-            "movaps %[tmp9],%%xmm5\n"        // a00
-            "psrld  $0x8,%%xmm4\n"           // ax.l>>8
-            "psrld  $0x8,%%xmm5\n"           // a00.h
-            "pand   vmask,%%xmm5\n"          // a00.h
-            "pmullw %%xmm0,%%xmm5\n"         // a00.h*vscale0
-            "movaps %[tmpa],%%xmm0\n"        // a01
-            "psrld  $0x8,%%xmm0\n"           // a01.h
-            "mov    %[count], %%edi\n"
-            "pand   vmask,%%xmm0\n"          // a01.h
-            "pand   vmask,%%xmm6\n"          // a10.h
-            "pmullw %%xmm1,%%xmm0\n"         // a01.h * vscale1
-            "add    $0xfffffffc,%%edi\n"
-            "pmullw %%xmm2,%%xmm6\n"         // a10.h * vscale2
-            "pand   vmask,%%xmm7\n"          // a11.h
-            "paddw  %%xmm0,%%xmm5\n"         // a00.h+a01.h
-            "pmullw %%xmm3,%%xmm7\n"         // a11.h * vscale2
-            "paddw  %%xmm6,%%xmm5\n"         // a00.h+a01.h+a10.h
-            "mov    %[colors],%%ecx\n"       // colors
-            "paddw  %%xmm7,%%xmm5\n"         // a00.h+a01.h+a10.h+a11.h
-            "pand   vmask,%%xmm4\n"          // ax.l & vmask
-            "pand   vmask2,%%xmm5\n"         // ax.h & vmask2
-            "addl   $0x10,%[colors]\n"       // colors+=4
-            "por    %%xmm5,%%xmm4\n"         // ax.l|ax.h
-            "movdqu %%xmm4,(%%ecx)\n"        // store colors
-            "cmp    $0x4,%%edi\n"
-            "mov    %%edi,%[count]\n"
-            "jge    1b\n"
-            :"+d" (xy)
-            : [srcAddr] "m" (srcAddr), [colors] "m" (colors), [rb] "m" (rb),
-            [count] "m" (count),
-            [tmp5] "m" (tmp5), [tmp6] "m" (tmp6), [tmp8] "m" (tmp8),
-            [tmp9] "m" (tmp9), [tmpa] "m" (tmpa)
-            :"memory","ecx","esi","edi", "eax"
-        );
-        } // count >= 4
-    }
-    while (count > 0)
-    {
-        data = *xy++;
-         y0 = data >> 14;
-        y1 = data & 0x3FFF;
-        subY = y0 & 0xF;
-        y0 >>= 4;
-
-        data = *xy++;
-        x0 = data >> 14;
-        x1 = data & 0x3FFF;
-        subX = x0 & 0xF;
-        x0 >>= 4;
-
-        row0 = (const SkPMColor*)(srcAddr + y0 * rb);
-        row1 = (const SkPMColor*)(srcAddr + y1 * rb);
-
-        Filter_32_opaque(subX, subY,
+           colors += 1;
+           --count;
+       }
+       if (count >= 4) {
+           __m128i tmp5, tmp6, tmp8, tmp9, tmpa;
+           __m128i vf = _mm_load_si128((__m128i*)&cvf);
+           __m128i vmask2 = _mm_load_si128((__m128i*)&cvmask2);
+           __m128i v256 = _mm_load_si128((__m128i*)&cv256);
+           __m128i vmask = _mm_load_si128((__m128i*)&cvmask);
+           tmp5 = _mm_setzero_si128();
+           tmp6 = _mm_setzero_si128();
+           tmp8 = _mm_setzero_si128();
+           tmp9 = _mm_setzero_si128();
+           tmpa = _mm_setzero_si128();
+
+           // load 4 pixes in each run [D, C, B, A]
+           __asm__(
+               "1:\n"
+               // load pixel A
+               "mov    (%%edx),%%edi\n"  // *xy
+               "mov    %%edi,%%ecx\n"
+               "shr    $0x12,%%edi\n"    // *xy > 0x12
+               "and    $0x3fff,%%ecx\n"  // *xy & 0x3FFF
+               "imul   %[rb],%%edi\n"    // rb * y0
+               "imul   %[rb],%%ecx\n"    // rb * y1
+
+               "mov    0x4(%%edx),%%eax\n" // *(xy + 4)
+               "mov    %%eax,%%esi\n"
+               "shr    $0x12,%%esi\n"      // x0
+               "add    %[srcAddr],%%ecx\n" // row1.0 = srcAddr + rb * y1
+               "and    $0x3fff,%%eax\n"    // x1
+               "add    %[srcAddr],%%edi\n" // row0.0 = srcAddr + rb * y0
+
+               "movd   (%%ecx,%%esi,4),%%xmm6\n"    // A: a10
+               "movd   (%%ecx,%%eax,4),%%xmm7\n"    // A: a11
+               // load pixel B
+               "mov    0x8(%%edx),%%ecx\n"          // *(xy+8)
+               "movd   (%%edi,%%esi,4),%%xmm4\n"    // A:a00
+               "movd   (%%edi,%%eax,4),%%xmm5\n"    // A:a01
+               "mov    %%ecx,%%esi\n"
+               "and    $0x3fff,%%ecx\n"      // B:y1
+               "shr    $0x12,%%esi\n"        // B:y0
+               "imul   %[rb],%%ecx\n"        // rb * y1
+               "imul   %[rb],%%esi\n"        // rb * y0
+               "mov    0xc(%%edx),%%edi\n"
+               "mov    %%edi,%%eax\n"
+               "shr    $0x12,%%eax\n"        // B:x0
+               "add    %[srcAddr],%%ecx\n"   // B:row1.1
+               "and    $0x3fff,%%edi\n"      // B:x1
+               "add    %[srcAddr],%%esi\n"   // B:row0.1
+               "movd   (%%ecx,%%eax,4),%%xmm2\n"    // B:a10
+               "movd   (%%ecx,%%edi,4),%%xmm1\n"    // B:a11
+               // load pixel C
+               "mov    0x10(%%edx),%%ecx\n"
+               "movd   (%%esi,%%eax,4),%%xmm0\n"    // B:a00
+               "movd   (%%esi,%%edi,4),%%xmm3\n"    // B:a01
+
+               "mov    %%ecx,%%eax\n"
+               "shr    $0x12,%%eax\n"               // C:y0
+               "and    $0x3fff,%%ecx\n"             // C:y1
+               "imul   %[rb],%%eax\n"
+               "imul   %[rb],%%ecx\n"
+               // [0, Ba00, 0, Aa00]
+               "punpcklqdq %%xmm0,%%xmm4\n"
+               // [0, Ba01, 0, Aa01]
+               "punpcklqdq %%xmm3,%%xmm5\n"
+               "mov    0x14(%%edx),%%esi\n"
+               "mov    %%esi,%%edi\n"
+               "add    %[srcAddr],%%eax\n"          // C: row0
+               "add    %[srcAddr],%%ecx\n"          // C: row1
+               // [0, Ba11, 0, Aa11]
+               "punpcklqdq %%xmm1,%%xmm7\n"
+               // [0, Ba10, 0, Aa10]
+               "punpcklqdq %%xmm2,%%xmm6\n"
+               "and    $0x3fff,%%esi\n"
+               "shr    $0x12,%%edi\n"
+               // [0, 0, 0, Ca01]
+               "movd   0x0(%%eax,%%esi,4),%%xmm3\n"
+               // [0, 0, 0, Ca11]
+               "movd   (%%ecx,%%esi,4),%%xmm2\n"
+               // load pixel D
+               "mov    0x18(%%edx),%%esi\n"
+               // [0, 0, 0, Ca00]
+               "movd   0x0(%%eax,%%edi,4),%%xmm1\n"
+               "mov    %%esi,%%eax\n"
+               "shr    $0x12,%%esi\n"            // D:y0
+               "and    $0x3fff,%%eax\n"          // D:y1
+               // [0, 0, 0, Ca10]
+               "movd   (%%ecx,%%edi,4),%%xmm0\n"
+
+               "imul   %[rb],%%eax\n"            // D:rb * y0
+               "imul   %[rb],%%esi\n"            // D:rb * y1
+
+               "movdqa %%xmm2,%[tmp6]\n"         // save D:a11
+               "movdqa %%xmm0,%[tmp5]\n"         // save D:a10
+
+
+               "mov    0x1c(%%edx),%%ecx\n"
+               "mov    %%ecx,%%edi\n"
+               "add    %[srcAddr],%%esi\n"       // D:row0
+               "and    $0x3fff,%%ecx\n"          // D:x1
+               "shr    $0x12,%%edi\n"            // D:x0
+               "add    %[srcAddr],%%eax\n"       // D:row1
+
+               "movd   (%%esi,%%ecx,4),%%xmm2\n"    // D:a01
+               "movd   (%%esi,%%edi,4),%%xmm0\n"    // D:a00
+
+               // [0, Da01, 0, Ca01]
+               "punpcklqdq %%xmm2,%%xmm3\n"
+               // [0, Da00, 0, Ca00]
+               "punpcklqdq %%xmm0,%%xmm1\n"
+
+               "mov 0x0(%%eax,%%edi,4), %%esi\n"       // D:a10
+               "mov %%esi, %[tmp8]\n"                  // save D:a10
+
+               "movd   0x0(%%eax,%%ecx,4),%%xmm2\n"    // D:a11
+               // [Da00, Ca00, Ba00, Aa00]
+               "shufps $0x88,%%xmm1,%%xmm4\n"
+               "movdqa %[tmp6],%%xmm1\n"        // C:a11
+               // [0, Da11, 0, Ca11]
+               "punpcklqdq %%xmm2,%%xmm1\n"
+               // [Da11, Ca11, Ba11, Aa11]
+               "shufps $0x88,%%xmm1,%%xmm7\n"   // a11.3210
+
+               "movdqa  (%%edx),%%xmm1\n"        // vy_d
+
+               "movaps %%xmm1,%%xmm2\n"         // vy_d
+               "shufps $0xdd,0x10(%%edx),%%xmm1\n"    // vx
+               "shufps $0x88,0x10(%%edx),%%xmm2\n"    // vy
+
+               "psrld  $0xe,%%xmm1\n"        // vx>>14
+               // [Da01, Ca01, Ba01, Aa01]
+               "shufps $0x88,%%xmm3,%%xmm5\n"
+               "psrld  $0xe,%%xmm2\n"         // vy>>14
+
+               "add    $0x20,%%edx\n"        // xy+=8
+               "movdqa %[tmp5],%%xmm3\n"     // C:a10
+               "movhpd %[tmp8],%%xmm3\n"     // CD:a10
+
+               "pand   %[vf],%%xmm1\n"           // vx & vf
+               "pand   %[vf],%%xmm2\n"           // vy & vf
+               // [Da10, Ca10, Ba10, Aa10]
+               "shufps $0x88,%%xmm3,%%xmm6\n"
+
+               "pshuflw $0xa0,%%xmm1,%%xmm3\n"
+               "pshuflw $0xa0,%%xmm2,%%xmm0\n"
+               "pshufhw $0xa0,%%xmm3,%%xmm1\n"
+               "pshufhw $0xa0,%%xmm0,%%xmm2\n"
+
+               "movdqa %%xmm1,%%xmm3\n"
+               "pmullw %%xmm2,%%xmm3\n"         // vxy
+
+               "psllw  $0x4,%%xmm2\n"           // v16y
+               "movdqa %[v256],%%xmm0\n"
+               "psllw  $0x4,%%xmm1\n"           // v16x
+
+               "paddw  %%xmm3,%%xmm0\n"         // v256+vxy
+               "psubw  %%xmm2,%%xmm0\n"         // v256+vxy-v16y
+               "psubw  %%xmm3,%%xmm2\n"         // v16y-vxy    vscale 2
+
+               "movaps %%xmm4,%[tmp9]\n"        // a00
+               "psubw  %%xmm1,%%xmm0\n"         // v256+vxy-v16y-v16x   vscale0
+
+               "movaps %%xmm5,%[tmpa]\n"        // a01
+
+               "psubw  %%xmm3,%%xmm1\n"         // v16x-vxy   vscale 1
+               "pand   %[vmask],%%xmm4\n"          // a00 & vmask
+               "pand   %[vmask],%%xmm5\n"          // a01 & vmask
+
+               "pmullw %%xmm0,%%xmm4\n"         // a00.l*vscale0\n
+               "pmullw %%xmm1,%%xmm5\n"         // a01.l*vscale1\n
+
+               "paddw  %%xmm5,%%xmm4\n"         // a00.l+a01.l
+               "movaps %%xmm6,%%xmm5\n"         // a10
+               "pand   %[vmask],%%xmm5\n"          // a10.l
+               "psrld  $0x8,%%xmm6\n"           // a10.h
+               "pmullw %%xmm2,%%xmm5\n"         // a10.l*vscale2
+               "paddw  %%xmm5,%%xmm4\n"         // a00.l+a01.l+a10.l
+               "movaps %%xmm7,%%xmm5\n"         // a11
+               "pand   %[vmask],%%xmm5\n"          // a11.l
+               "psrld  $0x8,%%xmm7\n"           // a11.h
+               "pmullw %%xmm3,%%xmm5\n"         // a11.l*vxy
+               "paddw  %%xmm5,%%xmm4\n"         // a00.l+a01.l+a10.l+a11.l
+               "movaps %[tmp9],%%xmm5\n"        // a00
+               "psrld  $0x8,%%xmm4\n"           // ax.l>>8
+               "psrld  $0x8,%%xmm5\n"           // a00.h
+               "pand   %[vmask],%%xmm5\n"          // a00.h
+               "pmullw %%xmm0,%%xmm5\n"         // a00.h*vscale0
+               "movaps %[tmpa],%%xmm0\n"        // a01
+               "psrld  $0x8,%%xmm0\n"           // a01.h
+               "mov    %[count], %%edi\n"
+               "pand   %[vmask],%%xmm0\n"          // a01.h
+               "pand   %[vmask],%%xmm6\n"          // a10.h
+               "pmullw %%xmm1,%%xmm0\n"         // a01.h * vscale1
+               "add    $0xfffffffc,%%edi\n"
+               "pmullw %%xmm2,%%xmm6\n"         // a10.h * vscale2
+               "pand   %[vmask],%%xmm7\n"          // a11.h
+               "paddw  %%xmm0,%%xmm5\n"         // a00.h+a01.h
+               "pmullw %%xmm3,%%xmm7\n"         // a11.h * vscale2
+               "paddw  %%xmm6,%%xmm5\n"         // a00.h+a01.h+a10.h
+               "mov    %[colors],%%ecx\n"       // colors
+               "paddw  %%xmm7,%%xmm5\n"         // a00.h+a01.h+a10.h+a11.h
+               "pand   %[vmask],%%xmm4\n"          // ax.l & vmask
+               "pand   %[vmask2],%%xmm5\n"         // ax.h & vmask2
+               "addl   $0x10,%[colors]\n"       // colors+=4
+               "por    %%xmm5,%%xmm4\n"         // ax.l|ax.h
+               "movdqu %%xmm4,(%%ecx)\n"        // store colors
+               "cmp    $0x4,%%edi\n"
+               "mov    %%edi,%[count]\n"
+               "jge    1b\n"
+               :"+d" (xy)
+               : [srcAddr] "m" (srcAddr), [colors] "m" (colors), [rb] "m" (rb),
+               [count] "m" (count), [tmp5] "m" (tmp5), [tmp6] "m" (tmp6), [tmp8] "m" (tmp8),
+               [tmp9] "m" (tmp9), [tmpa] "m" (tmpa), [vf] "m" (vf), [vmask2] "m" (vmask2),
+               [v256] "m" (v256), [vmask] "m" (vmask)
+               :"memory","ecx","esi","edi", "eax"
+           );
+       } // count >= 4
+   }
+   while (count > 0)
+   {
+       data = *xy++;
+       y0 = data >> 14;
+       y1 = data & 0x3FFF;
+       subY = y0 & 0xF;
+       y0 >>= 4;
+
+       data = *xy++;
+       x0 = data >> 14;
+       x1 = data & 0x3FFF;
+       subX = x0 & 0xF;
+       x0 >>= 4;
+
+       row0 = (const SkPMColor*)(srcAddr + y0 * rb);
+       row1 = (const SkPMColor*)(srcAddr + y1 * rb);
+
+       Filter_32_opaque(subX, subY,
                    (row0[x0]),
                    (row0[x1]),
                    (row1[x0]),
                    (row1[x1]),
                    colors);
-        colors += 1;
-        count --;
-    }
+       colors += 1;
+       count --;
+  }
 }
-
 void S32_alpha_D32_filter_DXDY_SSE2(const SkBitmapProcState& s,
                                   const uint32_t* xy,
                                   int count, uint32_t* colors) {
 
-    SkASSERT(count > 0 && colors != NULL);
-    SkASSERT(s.fDoFilter);
-    SkASSERT(s.fBitmap->config() == SkBitmap::kARGB_8888_Config);
-    SkASSERT(s.fAlphaScale < 256);
-    uint32_t data;
-    unsigned y0, y1, x0, x1, subX, subY;
-    const SkPMColor *row0, *row1;
-    const char* srcAddr = static_cast<const char*>(s.fBitmap->getPixels());
-    __m128i alphaScale = _mm_set1_epi16(s.fAlphaScale);
-    unsigned rb = s.fBitmap->rowBytes();
-    if (count >= 4) {
-        while (((size_t)xy & 0x0F) != 0)
-        {
-            data = *xy++;
-            y0 = data >> 14;
-            y1 = data & 0x3FFF;
-            subY = y0 & 0xF;
-            y0 >>= 4;
-
-            data = *xy++;
-            x0 = data >> 14;
-            x1 = data & 0x3FFF;
-            subX = x0 & 0xF;
-            x0 >>= 4;
-
-            row0 = (const SkPMColor*)(srcAddr + y0 * rb);
-            row1 = (const SkPMColor*)(srcAddr + y1 * rb);
-
-            Filter_32_alpha(subX, subY,
+   SkASSERT(count > 0 && colors != NULL);
+   SkASSERT(s.fDoFilter);
+   SkASSERT(s.fBitmap->config() == SkBitmap::kARGB_8888_Config);
+   SkASSERT(s.fAlphaScale < 256);
+   uint32_t data;
+   unsigned y0, y1, x0, x1, subX, subY;
+   const SkPMColor *row0, *row1;
+   const char* srcAddr = static_cast<const char*>(s.fBitmap->getPixels());
+   __m128i alphaScale = _mm_set1_epi16(s.fAlphaScale);
+   unsigned rb = s.fBitmap->rowBytes();
+   if (count >= 4) {
+       while (((size_t)xy & 0x0F) != 0)
+       {
+           data = *xy++;
+           y0 = data >> 14;
+           y1 = data & 0x3FFF;
+           subY = y0 & 0xF;
+           y0 >>= 4;
+
+           data = *xy++;
+           x0 = data >> 14;
+           x1 = data & 0x3FFF;
+           subX = x0 & 0xF;
+           x0 >>= 4;
+
+           row0 = (const SkPMColor*)(srcAddr + y0 * rb);
+           row1 = (const SkPMColor*)(srcAddr + y1 * rb);
+
+           Filter_32_alpha(subX, subY,
                        (row0[x0]),
                        (row0[x1]),
                        (row1[x0]),
                        (row1[x1]),
                        colors,
                        s.fAlphaScale);
-            colors += 1;
-            --count;
-        }
-    __m128i vf = _mm_set1_epi32(0xF);
-    __m128i vmask = _mm_set1_epi32(gMask_00FF00FF);
-    __m128i vmask2 = _mm_set1_epi32(0xff00ff00);
-    __m128i v256 = _mm_set1_epi16(256);
-    __m128i *d = reinterpret_cast<__m128i*>(colors);
-    while (count>=4) {
-        // [Bx1x0, By1y0, Ax1x0, Ay1y0]; load 4 pixes [D, C, B, A] in one run
-        __m128i vy_d = _mm_load_si128((__m128i*)xy);
-        // [Dx1x0, Dy1y0, Cx1x0, Cy1y0];
-        __m128i vx_d = _mm_load_si128((__m128i*)(xy+4));
-        // [Dy1y0, Cy1y0, By1y0, Ay1y0]
-        __m128i vy = (__m128i)_mm_shuffle_ps((__m128)vy_d,(__m128)vx_d,0x88);
-        // [Dx1x0, Cx1x0, Bx1x0, Ax1x0]
-        __m128i vx = (__m128i)_mm_shuffle_ps((__m128)vy_d,(__m128)vx_d,0xdd);
-
-        uint32_t XY = *xy++;
-        const uint32_t* row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
-        const uint32_t* row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
-
-        uint32_t XX = *xy++;    // x0:14 | 4 | x1:14
-        unsigned x0 = XX >> 18;
-        unsigned x1 = XX & 0x3FFF;
-        // [0, 0, 0, Ay0x0]
-        __m128i a00 = _mm_cvtsi32_si128(row0[x0]);
-        // [0, 0, 0, Ay0x1]
-        __m128i a01 = _mm_cvtsi32_si128(row0[x1]);
-        // [0, 0, 0, Ay1x0]
-        __m128i a10 = _mm_cvtsi32_si128(row1[x0]);
-        // [0, 0, 0, Ay1x1]
-        __m128i a11 = _mm_cvtsi32_si128(row1[x1]);
-
-        XY = *xy++;
-        row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
-        row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
-
-        XX = *xy++;    // x0:14 | 4 | x1:14
-        x0 = XX >> 18;
-        x1 = XX & 0x3FFF;
-        // [0, 0, By0x0, Ay0x0]
-        a00 = _mm_unpacklo_epi32(a00,_mm_cvtsi32_si128(row0[x0]));
-        // [0, 0, By0x1, Ay0x1]
-        a01 = _mm_unpacklo_epi32(a01,_mm_cvtsi32_si128(row0[x1]));
-        // [0, 0, By1x0, Ay1x0]
-        a10 = _mm_unpacklo_epi32(a10,_mm_cvtsi32_si128(row1[x0]));
-        // [0, 0, By1x1, Ay1x1]
-        a11 = _mm_unpacklo_epi32(a11,_mm_cvtsi32_si128(row1[x1]));
-
-        XY = *xy++;
-        row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
-        row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
-
-        XX = *xy++;    // x0:14 | 4 | x1:14
-        x0 = XX >> 18;
-        x1 = XX & 0x3FFF;
-        // [0, 0, 0, Cy0x0]
-        __m128i a00_d = _mm_cvtsi32_si128(row0[x0]);
-        // [0, 0, 0, Cy0x1]
-        __m128i a01_d = _mm_cvtsi32_si128(row0[x1]);
-        // [0, 0, 0, Cy1x0]
-        __m128i a10_d = _mm_cvtsi32_si128(row1[x0]);
-        // [0, 0, 0, Cy1x1]
-        __m128i a11_d = _mm_cvtsi32_si128(row1[x1]);
-
-        XY = *xy++;
-        row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
-        row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
-
-        XX = *xy++;    // x0:14 | 4 | x1:14
-        x0 = XX >> 18;
-        x1 = XX & 0x3FFF;
-        // [0, 0, Dy0x0, Cy0x0]
-        a00_d = _mm_unpacklo_epi32(a00_d,_mm_cvtsi32_si128(row0[x0]));
-        // [0, 0, Dy0x1, Cy0x1]
-        a01_d = _mm_unpacklo_epi32(a01_d,_mm_cvtsi32_si128(row0[x1]));
-        // [0, 0, Dy1x0, Cy1x0]
-        a10_d = _mm_unpacklo_epi32(a10_d,_mm_cvtsi32_si128(row1[x0]));
-        // [0, 0, Dy1x1, Cy1x1]
-        a11_d = _mm_unpacklo_epi32(a11_d,_mm_cvtsi32_si128(row1[x1]));
-
-        // [DsubX, CsubY, BsubY, AsubY]
-        vy = _mm_srli_epi32(vy,14);
-        vy = _mm_and_si128(vy,vf);
-
-        // [DsubX, CsubX, BsubX, AsubX]
-        vx = _mm_srli_epi32(vx,14);
-        vx = _mm_and_si128(vx,vf);
-
-        // [Dy0x0, Cy0x0, By0x0, Ay0x0]
-        a00 = _mm_unpacklo_epi64(a00,a00_d);
-        // [Dy0x1, Cy0x1, By0x1, Ay0x1]
-        a01 = _mm_unpacklo_epi64(a01,a01_d);
-        // [Dy1x0, Cy1x0, By1x0, Ay1x0]
-        a10 = _mm_unpacklo_epi64(a10,a10_d);
-        // [Dy1x1, Cy1x1, By1x1, Ay1x1]
-        a11 = _mm_unpacklo_epi64(a11,a11_d);
-
-        // [0, DsubX, 0, CsubY, BsubY, BsubY, AsubY, AsubY]
-        vy = _mm_shufflelo_epi16(vy,0xa0);
-        // [CsubY, DsubY, CsubY, CsubY, BsubY, BsubY, AsubY, AsubY]
-        vy = _mm_shufflehi_epi16(vy,0xa0);
-        vx = _mm_shufflelo_epi16(vx,0xa0);
-        // [CsubX, DsubX, CsubX, CsubX, BsubX, BsubX, AsubX, AsubX]
-        vx = _mm_shufflehi_epi16(vx,0xa0);
-
-        // unsigned xy = x * y;
-        __m128i vxy = _mm_mullo_epi16(vx,vy);
-        __m128i v16y = _mm_slli_epi16(vy,4);
-        __m128i v16x = _mm_slli_epi16(vx,4);
-        // unsigned scale = 256 - 16*y - 16*x + xy;
-        __m128i vscale = _mm_add_epi16(v256,vxy);
-        vscale = _mm_sub_epi16(vscale,v16y);
-        vscale = _mm_sub_epi16(vscale,v16x);
-
-        // uint32_t lo = (a00 & mask) * scale;
-        __m128i vlo = _mm_and_si128(a00,vmask);
-        vlo = _mm_mullo_epi16(vlo, vscale);
-
-        // uint32_t hi = ((a00 >> 8) & mask) * scale;
-        __m128i vhi = _mm_srli_epi32(a00,8);
-        vhi = _mm_and_si128(vhi,vmask);
-        vhi = _mm_mullo_epi16(vhi, vscale);
-        // scale = 16*x-xy;
-        vscale = _mm_sub_epi16(v16x,vxy);
-
-        // lo += (a01 & mask) * scale;
-        __m128i vlo2 = _mm_and_si128(a01,vmask);
-        vlo2 = _mm_mullo_epi16(vlo2, vscale);
-        vlo = _mm_add_epi16(vlo,vlo2);
-
-        // hi += ((a01 >> 8) & mask) * scale;
-        __m128i vhi2 = _mm_srli_epi32(a01,8);
-        vhi2 = _mm_and_si128(vhi2,vmask);
-        vhi2 = _mm_mullo_epi16(vhi2, vscale);
-        vhi = _mm_add_epi16(vhi,vhi2);
-
-        // scale = 16*y - xy;
-        vscale = _mm_sub_epi16(v16y,vxy);
-
-        // lo += (a10 & mask) * scale;
-        vlo2 = _mm_and_si128(a10,vmask);
-        vlo2 = _mm_mullo_epi16(vlo2, vscale);
-        vlo = _mm_add_epi16(vlo,vlo2);
-
-        // hi += ((a10 >> 8) & mask) * scale;
-        vhi2 = _mm_srli_epi32(a10,8);
-        vhi2 = _mm_and_si128(vhi2,vmask);
-        vhi2 = _mm_mullo_epi16(vhi2, vscale);
-        vhi = _mm_add_epi16(vhi,vhi2);
-
-        // lo += (a11 & mask) * xy;
-        vlo2 = _mm_and_si128(a11,vmask);
-        vlo2 = _mm_mullo_epi16(vlo2, vxy);
-        vlo = _mm_add_epi16(vlo,vlo2);
-
-        // hi += ((a11 >> 8) & mask) * xy;
-        vhi2 = _mm_srli_epi32(a11,8);
-        vhi2 = _mm_and_si128(vhi2,vmask);
-        vhi2 = _mm_mullo_epi16(vhi2, vxy);
-        vhi = _mm_add_epi16(vhi,vhi2);
-
-        // lo = (((lo >> 8) & mask) * alphaScale) >> 8 & mask;
-        vlo = _mm_srli_epi32(vlo,8);
-        vlo = _mm_mullo_epi16(_mm_and_si128(vlo,vmask), alphaScale);
-        vlo = _mm_srli_epi32(vlo,8);
-        vlo = _mm_and_si128(vlo,vmask);
-
-        // hi = (((hi >> 8) & mask) * alphaScale) >> 8 &(~mask);
-        vhi = _mm_srli_epi32(vhi,8);
-        vhi = _mm_mullo_epi16(_mm_and_si128(vhi,vmask), alphaScale);
-        vhi = _mm_and_si128(vhi, vmask2);
-
-        _mm_storeu_si128(d,_mm_or_si128(vlo,vhi));
-        d++;
-        count -= 4;
-        }
-        colors = reinterpret_cast<SkPMColor*>(d);
-    }
-    while (count > 0)
-    {
-        data = *xy++;
-        y0 = data >> 14;
-        y1 = data & 0x3FFF;
-        subY = y0 & 0xF;
-        y0 >>= 4;
-
-        data = *xy++;
-        x0 = data >> 14;
-        x1 = data & 0x3FFF;
-        subX = x0 & 0xF;
-        x0 >>= 4;
-
-        row0 = (const SkPMColor*)(srcAddr + y0 * rb);
-        row1 = (const SkPMColor*)(srcAddr + y1 * rb);
-
-        Filter_32_alpha(subX, subY,
+           colors += 1;
+           --count;
+       }
+       __m128i vf = _mm_set1_epi32(0xF);
+       __m128i vmask = _mm_set1_epi32(gMask_00FF00FF);
+       __m128i vmask2 = _mm_set1_epi32(0xff00ff00);
+       __m128i v256 = _mm_set1_epi16(256);
+       __m128i *d = reinterpret_cast<__m128i*>(colors);
+       while (count>=4) {
+           // [Bx1x0, By1y0, Ax1x0, Ay1y0]; load 4 pixes [D, C, B, A] in one run
+           __m128i vy_d = _mm_load_si128((__m128i*)xy);
+           // [Dx1x0, Dy1y0, Cx1x0, Cy1y0];
+           __m128i vx_d = _mm_load_si128((__m128i*)(xy+4));
+           // [Dy1y0, Cy1y0, By1y0, Ay1y0]
+           __m128i vy = (__m128i)_mm_shuffle_ps((__m128)vy_d,(__m128)vx_d,0x88);
+           // [Dx1x0, Cx1x0, Bx1x0, Ax1x0]
+           __m128i vx = (__m128i)_mm_shuffle_ps((__m128)vy_d,(__m128)vx_d,0xdd);
+
+           uint32_t XY = *xy++;
+           const uint32_t* row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
+           const uint32_t* row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
+
+           uint32_t XX = *xy++;    // x0:14 | 4 | x1:14
+           unsigned x0 = XX >> 18;
+           unsigned x1 = XX & 0x3FFF;
+           // [0, 0, 0, Ay0x0]
+           __m128i a00 = _mm_cvtsi32_si128(row0[x0]);
+           // [0, 0, 0, Ay0x1]
+           __m128i a01 = _mm_cvtsi32_si128(row0[x1]);
+           // [0, 0, 0, Ay1x0]
+           __m128i a10 = _mm_cvtsi32_si128(row1[x0]);
+           // [0, 0, 0, Ay1x1]
+           __m128i a11 = _mm_cvtsi32_si128(row1[x1]);
+
+           XY = *xy++;
+           row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
+           row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
+
+           XX = *xy++;    // x0:14 | 4 | x1:14
+           x0 = XX >> 18;
+           x1 = XX & 0x3FFF;
+           // [0, 0, By0x0, Ay0x0]
+           a00 = _mm_unpacklo_epi32(a00,_mm_cvtsi32_si128(row0[x0]));
+           // [0, 0, By0x1, Ay0x1]
+           a01 = _mm_unpacklo_epi32(a01,_mm_cvtsi32_si128(row0[x1]));
+           // [0, 0, By1x0, Ay1x0]
+           a10 = _mm_unpacklo_epi32(a10,_mm_cvtsi32_si128(row1[x0]));
+           // [0, 0, By1x1, Ay1x1]
+           a11 = _mm_unpacklo_epi32(a11,_mm_cvtsi32_si128(row1[x1]));
+
+           XY = *xy++;
+           row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
+           row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
+
+           XX = *xy++;    // x0:14 | 4 | x1:14
+           x0 = XX >> 18;
+           x1 = XX & 0x3FFF;
+           // [0, 0, 0, Cy0x0]
+           __m128i a00_d = _mm_cvtsi32_si128(row0[x0]);
+           // [0, 0, 0, Cy0x1]
+           __m128i a01_d = _mm_cvtsi32_si128(row0[x1]);
+           // [0, 0, 0, Cy1x0]
+           __m128i a10_d = _mm_cvtsi32_si128(row1[x0]);
+           // [0, 0, 0, Cy1x1]
+           __m128i a11_d = _mm_cvtsi32_si128(row1[x1]);
+
+           XY = *xy++;
+           row0 = (const uint32_t*)(srcAddr + (XY >> 18) * rb);
+           row1 = (const uint32_t*)(srcAddr + (XY & 0x3FFF) * rb);
+
+           XX = *xy++;    // x0:14 | 4 | x1:14
+           x0 = XX >> 18;
+           x1 = XX & 0x3FFF;
+           // [0, 0, Dy0x0, Cy0x0]
+           a00_d = _mm_unpacklo_epi32(a00_d,_mm_cvtsi32_si128(row0[x0]));
+           // [0, 0, Dy0x1, Cy0x1]
+           a01_d = _mm_unpacklo_epi32(a01_d,_mm_cvtsi32_si128(row0[x1]));
+           // [0, 0, Dy1x0, Cy1x0]
+           a10_d = _mm_unpacklo_epi32(a10_d,_mm_cvtsi32_si128(row1[x0]));
+           // [0, 0, Dy1x1, Cy1x1]
+           a11_d = _mm_unpacklo_epi32(a11_d,_mm_cvtsi32_si128(row1[x1]));
+
+           // [DsubX, CsubY, BsubY, AsubY]
+           vy = _mm_srli_epi32(vy,14);
+           vy = _mm_and_si128(vy,vf);
+
+           // [DsubX, CsubX, BsubX, AsubX]
+           vx = _mm_srli_epi32(vx,14);
+           vx = _mm_and_si128(vx,vf);
+
+           // [Dy0x0, Cy0x0, By0x0, Ay0x0]
+           a00 = _mm_unpacklo_epi64(a00,a00_d);
+           // [Dy0x1, Cy0x1, By0x1, Ay0x1]
+           a01 = _mm_unpacklo_epi64(a01,a01_d);
+           // [Dy1x0, Cy1x0, By1x0, Ay1x0]
+           a10 = _mm_unpacklo_epi64(a10,a10_d);
+           // [Dy1x1, Cy1x1, By1x1, Ay1x1]
+           a11 = _mm_unpacklo_epi64(a11,a11_d);
+
+           // [0, DsubX, 0, CsubY, BsubY, BsubY, AsubY, AsubY]
+           vy = _mm_shufflelo_epi16(vy,0xa0);
+           // [CsubY, DsubY, CsubY, CsubY, BsubY, BsubY, AsubY, AsubY]
+           vy = _mm_shufflehi_epi16(vy,0xa0);
+           vx = _mm_shufflelo_epi16(vx,0xa0);
+           // [CsubX, DsubX, CsubX, CsubX, BsubX, BsubX, AsubX, AsubX]
+           vx = _mm_shufflehi_epi16(vx,0xa0);
+
+           // unsigned xy = x * y;
+           __m128i vxy = _mm_mullo_epi16(vx,vy);
+           __m128i v16y = _mm_slli_epi16(vy,4);
+           __m128i v16x = _mm_slli_epi16(vx,4);
+           // unsigned scale = 256 - 16*y - 16*x + xy;
+           __m128i vscale = _mm_add_epi16(v256,vxy);
+           vscale = _mm_sub_epi16(vscale,v16y);
+           vscale = _mm_sub_epi16(vscale,v16x);
+
+           // uint32_t lo = (a00 & mask) * scale;
+           __m128i vlo = _mm_and_si128(a00,vmask);
+           vlo = _mm_mullo_epi16(vlo, vscale);
+
+           // uint32_t hi = ((a00 >> 8) & mask) * scale;
+           __m128i vhi = _mm_srli_epi32(a00,8);
+           vhi = _mm_and_si128(vhi,vmask);
+           vhi = _mm_mullo_epi16(vhi, vscale);
+           // scale = 16*x-xy;
+           vscale = _mm_sub_epi16(v16x,vxy);
+
+           // lo += (a01 & mask) * scale;
+           __m128i vlo2 = _mm_and_si128(a01,vmask);
+           vlo2 = _mm_mullo_epi16(vlo2, vscale);
+           vlo = _mm_add_epi16(vlo,vlo2);
+
+           // hi += ((a01 >> 8) & mask) * scale;
+           __m128i vhi2 = _mm_srli_epi32(a01,8);
+           vhi2 = _mm_and_si128(vhi2,vmask);
+           vhi2 = _mm_mullo_epi16(vhi2, vscale);
+           vhi = _mm_add_epi16(vhi,vhi2);
+
+           // scale = 16*y - xy;
+           vscale = _mm_sub_epi16(v16y,vxy);
+
+           // lo += (a10 & mask) * scale;
+           vlo2 = _mm_and_si128(a10,vmask);
+           vlo2 = _mm_mullo_epi16(vlo2, vscale);
+           vlo = _mm_add_epi16(vlo,vlo2);
+
+           // hi += ((a10 >> 8) & mask) * scale;
+           vhi2 = _mm_srli_epi32(a10,8);
+           vhi2 = _mm_and_si128(vhi2,vmask);
+           vhi2 = _mm_mullo_epi16(vhi2, vscale);
+           vhi = _mm_add_epi16(vhi,vhi2);
+
+           // lo += (a11 & mask) * xy;
+           vlo2 = _mm_and_si128(a11,vmask);
+           vlo2 = _mm_mullo_epi16(vlo2, vxy);
+           vlo = _mm_add_epi16(vlo,vlo2);
+
+           // hi += ((a11 >> 8) & mask) * xy;
+           vhi2 = _mm_srli_epi32(a11,8);
+           vhi2 = _mm_and_si128(vhi2,vmask);
+           vhi2 = _mm_mullo_epi16(vhi2, vxy);
+           vhi = _mm_add_epi16(vhi,vhi2);
+
+           // lo = (((lo >> 8) & mask) * alphaScale) >> 8 & mask;
+           vlo = _mm_srli_epi32(vlo,8);
+           vlo = _mm_mullo_epi16(_mm_and_si128(vlo,vmask), alphaScale);
+           vlo = _mm_srli_epi32(vlo,8);
+           vlo = _mm_and_si128(vlo,vmask);
+
+           // hi = (((hi >> 8) & mask) * alphaScale) >> 8 &(~mask);
+           vhi = _mm_srli_epi32(vhi,8);
+           vhi = _mm_mullo_epi16(_mm_and_si128(vhi,vmask), alphaScale);
+           vhi = _mm_and_si128(vhi, vmask2);
+           _mm_storeu_si128(d,_mm_or_si128(vlo,vhi));
+           d++;
+           count -= 4;
+       }
+       colors = reinterpret_cast<SkPMColor*>(d);
+   }
+   while (count > 0)
+   {
+       data = *xy++;
+       y0 = data >> 14;
+       y1 = data & 0x3FFF;
+       subY = y0 & 0xF;
+       y0 >>= 4;
+
+       data = *xy++;
+       x0 = data >> 14;
+       x1 = data & 0x3FFF;
+       subX = x0 & 0xF;
+       x0 >>= 4;
+
+       row0 = (const SkPMColor*)(srcAddr + y0 * rb);
+       row1 = (const SkPMColor*)(srcAddr + y1 * rb);
+
+       Filter_32_alpha(subX, subY,
                        (row0[x0]),
                        (row0[x1]),
                        (row1[x0]),
                        (row1[x1]),
                        colors,
                        s.fAlphaScale);
-        colors += 1;
-        count --;
-    }
-
+       colors += 1;
+       count --;
+  }
 }
-
 void S32_alpha_D32_filter_DXDY_SSE2_asm(const SkBitmapProcState& s,
                                   const uint32_t* xy,
                                   int count, uint32_t* colors) {
-    SkASSERT(count > 0 && colors != NULL);
-    SkASSERT(s.fDoFilter);
-    SkASSERT(s.fBitmap->config() == SkBitmap::kARGB_8888_Config);
-    SkASSERT(s.fAlphaScale < 256);
-    uint32_t data;
-    unsigned y0, y1, x0, x1, subX, subY;
-    const SkPMColor *row0, *row1;
-    const char* srcAddr = static_cast<const char*>(s.fBitmap->getPixels());
-    unsigned rb = s.fBitmap->rowBytes();
-    unsigned alphaScale = s.fAlphaScale;
-    if (count >= 4) {
-        while (((size_t)xy & 0x0F) != 0)
-        {
-            data = *xy++;
-            y0 = data >> 14;
-            y1 = data & 0x3FFF;
-            subY = y0 & 0xF;
-            y0 >>= 4;
-
-            data = *xy++;
-            x0 = data >> 14;
-            x1 = data & 0x3FFF;
-            subX = x0 & 0xF;
-            x0 >>= 4;
-
-            row0 = (const SkPMColor*)(srcAddr + y0 * rb);
-            row1 = (const SkPMColor*)(srcAddr + y1 * rb);
-
-            Filter_32_alpha(subX, subY,
+   SkASSERT(count > 0 && colors != NULL);
+   SkASSERT(s.fDoFilter);
+   SkASSERT(s.fBitmap->config() == SkBitmap::kARGB_8888_Config);
+   SkASSERT(s.fAlphaScale < 256);
+   uint32_t data;
+   unsigned y0, y1, x0, x1, subX, subY;
+   const SkPMColor *row0, *row1;
+   const char* srcAddr = static_cast<const char*>(s.fBitmap->getPixels());
+   unsigned rb = s.fBitmap->rowBytes();
+   unsigned alphaScale = s.fAlphaScale;
+   if (count >= 4) {
+       while (((size_t)xy & 0x0F) != 0) {
+           data = *xy++;
+           y0 = data >> 14;
+           y1 = data & 0x3FFF;
+           subY = y0 & 0xF;
+           y0 >>= 4;
+
+           data = *xy++;
+           x0 = data >> 14;
+           x1 = data & 0x3FFF;
+           subX = x0 & 0xF;
+           x0 >>= 4;
+
+           row0 = (const SkPMColor*)(srcAddr + y0 * rb);
+           row1 = (const SkPMColor*)(srcAddr + y1 * rb);
+
+           Filter_32_alpha(subX, subY,
                        (row0[x0]),
                        (row0[x1]),
                        (row1[x0]),
                        (row1[x1]),
                       colors,
                        s.fAlphaScale);
-            colors += 1;
-            --count;
-        }
-
-        // BE CAREFUL, count >= 4
-        if (count >= 4)
-        {
-           __attribute__((aligned(16)))
+           colors += 1;
+           --count;
+       }
+       // BE CAREFUL, count >= 4
+       if (count >= 4)
+       {
            __m128i tmp5, tmp6, tmp8, tmp9, tmpa, tmpb;
+           // prepare the const varibles for asm code
+           __m128i vf = _mm_load_si128((__m128i*)&cvf);
+           __m128i vmask2 = _mm_load_si128((__m128i*)&cvmask2);
+           __m128i v256 = _mm_load_si128((__m128i*)&cv256);
+           __m128i vmask = _mm_load_si128((__m128i*)&cvmask);
            tmp5 = _mm_setzero_si128();
            tmp6 = _mm_setzero_si128();
            tmp8 = _mm_setzero_si128();
            tmp9 = _mm_setzero_si128();
            tmpa = _mm_setzero_si128();
            tmpb = _mm_setzero_si128();
-           // unsigned int tmpeax;
-            __asm__(
-           // "mov   %%eax, %[tmpeax]\n"
+           __asm__(
            "movd   %[alphaScale], %%xmm0\n"
            "pshuflw $0,%%xmm0,%%xmm0\n"
            "punpcklqdq %%xmm0,%%xmm0\n"    // a00._1_0
@@ -1625,14 +1622,12 @@ void S32_alpha_D32_filter_DXDY_SSE2_asm(const SkBitmapProcState& s,
            "and    $0x3fff,%%ecx\n"
            "imul   %[rb],%%edi\n"
            "imul   %[rb],%%ecx\n"
-
            "mov    0x4(%%edx),%%eax\n"
            "mov    %%eax,%%esi\n"
            "shr    $0x12,%%esi\n"
            "add    %[srcAddr],%%ecx\n"    // row1.0
            "and    $0x3fff,%%eax\n"
            "add    %[srcAddr],%%edi\n"    // row0.0
-
            "movd   (%%ecx,%%esi,4),%%xmm6\n"    // a10.0
            "movd   (%%ecx,%%eax,4),%%xmm7\n"    // a11.0
            "mov    0x8(%%edx),%%ecx\n"
@@ -1643,10 +1638,6 @@ void S32_alpha_D32_filter_DXDY_SSE2_asm(const SkBitmapProcState& s,
            "shr    $0x12,%%esi\n"
            "imul   %[rb],%%ecx\n"
            "imul   %[rb],%%esi\n"
-
-           // "movaps %%xmm6,%[tmp1]\n"    // a10.0
-           // "movaps %%xmm7,%[tmp2]\n"    // a11.0
-
            "mov    0xc(%%edx),%%edi\n"
            "mov    %%edi,%%eax\n"
            "shr    $0x12,%%eax\n"
@@ -1658,19 +1649,13 @@ void S32_alpha_D32_filter_DXDY_SSE2_asm(const SkBitmapProcState& s,
            "mov    0x10(%%edx),%%ecx\n"
            "movd   (%%esi,%%eax,4),%%xmm0\n"    // a00.1
            "movd   (%%esi,%%edi,4),%%xmm3\n"    // a01.1
-
            "mov    %%ecx,%%eax\n"
            "shr    $0x12,%%eax\n"
            "and    $0x3fff,%%ecx\n"
            "imul   %[rb],%%eax\n"
            "imul   %[rb],%%ecx\n"
-
            "punpcklqdq %%xmm0,%%xmm4\n"    // a00._1_0
            "punpcklqdq %%xmm3,%%xmm5\n"    // a01._1_0
-
-           // "movdqa %%xmm2,%[tmp3]\n"    // a10.1
-           // "movdqa %%xmm1,%[tmp4]\n"    // a11.1
-
            "mov    0x14(%%edx),%%esi\n"
            "mov    %%esi,%%edi\n"
            "add    %[srcAddr],%%eax\n"        // row0.2
@@ -1679,148 +1664,109 @@ void S32_alpha_D32_filter_DXDY_SSE2_asm(const SkBitmapProcState& s,
            "punpcklqdq %%xmm2,%%xmm6\n"    // a10._1_0
            "and    $0x3fff,%%esi\n"
            "shr    $0x12,%%edi\n"
-
-           // "movaps %%xmm6,%[tmp1]\n"    // a10.0
-
-
-           // "movaps %[tmp2],%%xmm7\n"        // a11.0
-           // "movhpd %[tmp4],%%xmm7\n"        // a11._1_0
-
-           "movd   0x0(%%eax,%%esi,4),%%xmm3\n"    // a01.2
+           "movd   0x0(%%eax,%%esi,4),%%xmm3\n" // a01.2
            "movd   (%%ecx,%%esi,4),%%xmm2\n"    // a11.2
            "mov    0x18(%%edx),%%esi\n"
-           "movd   0x0(%%eax,%%edi,4),%%xmm1\n"    // a00.2
+           "movd   0x0(%%eax,%%edi,4),%%xmm1\n" // a00.2
            "mov    %%esi,%%eax\n"
            "shr    $0x12,%%esi\n"
            "and    $0x3fff,%%eax\n"
            "movd   (%%ecx,%%edi,4),%%xmm0\n"    // a10.2
-
            "imul   %[rb],%%eax\n"
            "imul   %[rb],%%esi\n"
-
            "movdqa %%xmm2,%[tmp6]\n"        // a11.2
            "movdqa %%xmm0,%[tmp5]\n"        // a10.2
-
-
            "mov    0x1c(%%edx),%%ecx\n"
            "mov    %%ecx,%%edi\n"
-           "add    %[srcAddr],%%esi\n"            // row0.3
-           "and    $0x3fff,%%ecx\n"        // x1.3
-           "shr    $0x12,%%edi\n"            // x0.3
-           "add    %[srcAddr],%%eax\n"    // row1.3
-
-           "movd   (%%esi,%%ecx,4),%%xmm2\n"    // a01.3
-           "movd   (%%esi,%%edi,4),%%xmm0\n"    // a00.3
-
-           // "movdqa %%xmm2,%[tmp7]\n"        // a01.3 save
-           "punpcklqdq %%xmm2,%%xmm3\n"        // a01._3_2
-           "punpcklqdq %%xmm0,%%xmm1\n"        // a00._3_2
-
-           // "movd   0x0(%%eax,%%edi,4),%%xmm2\n"    // a10.3
-           // "movdqa %%xmm2,%[tmp8]\n"        // 10.3
+           "add    %[srcAddr],%%esi\n"      // row0.3
+           "and    $0x3fff,%%ecx\n"         // x1.3
+           "shr    $0x12,%%edi\n"           // x0.3
+           "add    %[srcAddr],%%eax\n"      // row1.3
+           "movd   (%%esi,%%ecx,4),%%xmm2\n" // a01.3
+           "movd   (%%esi,%%edi,4),%%xmm0\n" // a00.3
+           "punpcklqdq %%xmm2,%%xmm3\n"     // a01._3_2
+           "punpcklqdq %%xmm0,%%xmm1\n"     // a00._3_2
            "mov 0x0(%%eax,%%edi,4), %%esi\n"  // a10.3
            "mov %%esi, %[tmp8]\n"             // a10.3
-
-           "movd   0x0(%%eax,%%ecx,4),%%xmm2\n"    // a11.3
-
-           "shufps $0x88,%%xmm1,%%xmm4\n"        // a00.3210
+           "movd   0x0(%%eax,%%ecx,4),%%xmm2\n" // a11.3
+           "shufps $0x88,%%xmm1,%%xmm4\n"       // a00.3210
            "movdqa %[tmp6],%%xmm1\n"        // a11.2
-
            "punpcklqdq %%xmm2,%%xmm1\n"        // a11._3_2
-
-           "shufps $0x88,%%xmm1,%%xmm7\n"        // a11.3210
-
+           "shufps $0x88,%%xmm1,%%xmm7\n"      // a11.3210
            "movdqa (%%edx),%%xmm1\n"        // vy_d
-           // "movhpd %[tmp7],%%xmm3\n"        // a01._3_2
-
-           "movaps %%xmm1,%%xmm2\n"        // vy_d
+           "movaps %%xmm1,%%xmm2\n"         // vy_d
            "shufps $0xdd,0x10(%%edx),%%xmm1\n"    // vx
            "shufps $0x88,0x10(%%edx),%%xmm2\n"    // vy
-
            "psrld  $0xe,%%xmm1\n"        // vx>>14
            "shufps $0x88,%%xmm3,%%xmm5\n"    // a01.3210
            "psrld  $0xe,%%xmm2\n"        // vy>>14
-
-           // "movaps %[tmp1],%%xmm6\n"        // a10._1_0
            "add    $0x20,%%edx\n"        // xy+=8
-           "movdqa %[tmp5],%%xmm3\n"        // a10.2
-           // "movhpd %[tmp3],%%xmm6\n"        // a10._1_0
-           "movhpd %[tmp8],%%xmm3\n"        // a10._3_2
-
-           "pand   vf,%%xmm1\n"        // vx & vf
-           "pand   vf,%%xmm2\n"        // vy & vf
-
+           "movdqa %[tmp5],%%xmm3\n"     // a10.2
+           "movhpd %[tmp8],%%xmm3\n"     // a10._3_2
+           "pand   %[vf],%%xmm1\n"        // vx & vf
+           "pand   %[vf],%%xmm2\n"        // vy & vf
            "shufps $0x88,%%xmm3,%%xmm6\n"    // a10.3210
-
            "pshuflw $0xa0,%%xmm1,%%xmm3\n"
            "pshuflw $0xa0,%%xmm2,%%xmm0\n"
            "pshufhw $0xa0,%%xmm3,%%xmm1\n"
            "pshufhw $0xa0,%%xmm0,%%xmm2\n"
-
            "movdqa %%xmm1,%%xmm3\n"
-           "pmullw %%xmm2,%%xmm3\n"        // vxy
-
+           "pmullw %%xmm2,%%xmm3\n"      // vxy
            "psllw  $0x4,%%xmm2\n"        // v16y
-           "movdqa v256,%%xmm0\n"
+           "movdqa %[v256],%%xmm0\n"
            "psllw  $0x4,%%xmm1\n"        // v16x
-
-           "paddw  %%xmm3,%%xmm0\n"        // v256+vxy
-           "psubw  %%xmm2,%%xmm0\n"        // v256+vxy-v16y
-           "psubw  %%xmm3,%%xmm2\n"        // v16y-vxy    vscale 2
-
-           "movaps %%xmm4,%[tmp9]\n"        // a00
-           "psubw  %%xmm1,%%xmm0\n"        // v256+vxy-v16y-v16x   vscale0
-
-           "movaps %%xmm5,%[tmpa]\n"        // a01
-
-           "psubw  %%xmm3,%%xmm1\n"        // v16x-vxy   vscale 1
-           "pand   vmask,%%xmm4\n"        // a00 & vmask
-           "pmullw %%xmm0,%%xmm4\n"        // a00.l*vscale0\n
-           "pand   vmask,%%xmm5\n"        // a01 & vmask
-           "pmullw %%xmm1,%%xmm5\n"        // a01.l*vscale1\n
-
-           "paddw  %%xmm5,%%xmm4\n"        // a00.l+a01.l
-           "movaps %%xmm6,%%xmm5\n"        // a10
-           "pand   vmask,%%xmm5\n"        // a10.l
+           "paddw  %%xmm3,%%xmm0\n"      // v256+vxy
+           "psubw  %%xmm2,%%xmm0\n"      // v256+vxy-v16y
+           "psubw  %%xmm3,%%xmm2\n"      // v16y-vxy    vscale 2
+           "movaps %%xmm4,%[tmp9]\n"     // a00
+           "psubw  %%xmm1,%%xmm0\n"      // v256+vxy-v16y-v16x   vscale0
+           "movaps %%xmm5,%[tmpa]\n"     // a01
+           "psubw  %%xmm3,%%xmm1\n"      // v16x-vxy   vscale 1
+           "pand   %[vmask],%%xmm4\n"       // a00 & vmask
+           "pmullw %%xmm0,%%xmm4\n"      // a00.l*vscale0\n
+           "pand   %[vmask],%%xmm5\n"       // a01 & vmask
+           "pmullw %%xmm1,%%xmm5\n"      // a01.l*vscale1\n
+           "paddw  %%xmm5,%%xmm4\n"      // a00.l+a01.l
+           "movaps %%xmm6,%%xmm5\n"      // a10
+           "pand   %[vmask],%%xmm5\n"       // a10.l
            "psrld  $0x8,%%xmm6\n"        // a10.h
-           "pmullw %%xmm2,%%xmm5\n"        // a10.l*vscale2
-           "paddw  %%xmm5,%%xmm4\n"        // a00.l+a01.l+a10.l
-           "movaps %%xmm7,%%xmm5\n"        // a11
-           "pand   vmask,%%xmm5\n"        // a11.l
+           "pmullw %%xmm2,%%xmm5\n"      // a10.l*vscale2
+           "paddw  %%xmm5,%%xmm4\n"      // a00.l+a01.l+a10.l
+           "movaps %%xmm7,%%xmm5\n"      // a11
+           "pand   %[vmask],%%xmm5\n"       // a11.l
            "psrld  $0x8,%%xmm7\n"        // a11.h
-           "pmullw %%xmm3,%%xmm5\n"        // a11.l*vxy
-           "paddw  %%xmm5,%%xmm4\n"        // a00.l+a01.l+a10.l+a11.l
-           "movaps %[tmp9],%%xmm5\n"        // a00
+           "pmullw %%xmm3,%%xmm5\n"      // a11.l*vxy
+           "paddw  %%xmm5,%%xmm4\n"      // a00.l+a01.l+a10.l+a11.l
+           "movaps %[tmp9],%%xmm5\n"     // a00
            "psrld  $0x8,%%xmm4\n"        // ax.l>>8
            "psrld  $0x8,%%xmm5\n"        // a00.h
-           "pand   vmask,%%xmm4\n"        // ax.l & vmask
-           "pand   vmask,%%xmm5\n"        // a00.h
-           "pmullw %%xmm0,%%xmm5\n"        // a00.h*vscale0
-           "movaps %[tmpa],%%xmm0\n"        // a01
+           "pand   %[vmask],%%xmm4\n"       // ax.l & vmask
+           "pand   %[vmask],%%xmm5\n"       // a00.h
+           "pmullw %%xmm0,%%xmm5\n"      // a00.h*vscale0
+           "movaps %[tmpa],%%xmm0\n"     // a01
            "psrld  $0x8,%%xmm0\n"        // a01.h
            "mov    %[count], %%edi\n"
-           "pand   vmask,%%xmm0\n"        // a01.h
-           "pmullw %%xmm1,%%xmm0\n"        // a01.h * vscale1
-           "pand   vmask,%%xmm6\n"        // a10.h
+           "pand   %[vmask],%%xmm0\n"       // a01.h
+           "pmullw %%xmm1,%%xmm0\n"      // a01.h * vscale1
+           "pand   %[vmask],%%xmm6\n"       // a10.h
            "add    $0xfffffffc,%%edi\n"
-           "pmullw %%xmm2,%%xmm6\n"        // a10.h * vscale2
-           "pand   vmask,%%xmm7\n"        // a11.h
-           "paddw  %%xmm0,%%xmm5\n"        // a00.h+a01.h
-           "pmullw %%xmm3,%%xmm7\n"        // a11.h * vscale2
-           // "movaps %[tmpb], %%xmm3\n"
-           "paddw  %%xmm6,%%xmm5\n"        // a00.h+a01.h+a10.h
+           "pmullw %%xmm2,%%xmm6\n"      // a10.h * vscale2
+           "pand   %[vmask],%%xmm7\n"       // a11.h
+           "paddw  %%xmm0,%%xmm5\n"      // a00.h+a01.h
+           "pmullw %%xmm3,%%xmm7\n"      // a11.h * vscale2
+           "paddw  %%xmm6,%%xmm5\n"      // a00.h+a01.h+a10.h
            "pmullw %[tmpb], %%xmm4\n"
-           "mov    %[colors],%%ecx\n"        // colors
-           "paddw  %%xmm7,%%xmm5\n"        // a00.h+a01.h+a10.h+a11.h
+           "mov    %[colors],%%ecx\n"    // colors
+           "paddw  %%xmm7,%%xmm5\n"      // a00.h+a01.h+a10.h+a11.h
            "psrld  $0x8,%%xmm5\n"        // ax.l>>8
-           "pand   vmask,%%xmm5\n"        // ax.l & vmask
+           "pand   %[vmask],%%xmm5\n"       // ax.l & vmask
            "pmullw %[tmpb], %%xmm5\n"
            "psrld  $0x8,%%xmm4\n"        // ax.l>>8
-           "pand   vmask,%%xmm4\n"        // ax.l & vmask
-           "pand   vmask2,%%xmm5\n"        // ax.h & vmask2
-           "addl   $0x10,%[colors]\n"        // colors+=4
-           "por    %%xmm5,%%xmm4\n"        // ax.l|ax.h
-           "movdqu %%xmm4,(%%ecx)\n"        // store colors
+           "pand   %[vmask],%%xmm4\n"       // ax.l & vmask
+           "pand   %[vmask2],%%xmm5\n"      // ax.h & vmask2
+           "addl   $0x10,%[colors]\n"    // colors+=4
+           "por    %%xmm5,%%xmm4\n"      // ax.l|ax.h
+           "movdqu %%xmm4,(%%ecx)\n"     // store colors
            "cmp    $0x4,%%edi\n"
            "mov    %%edi,%[count]\n"
            "jge    1b\n"
@@ -1828,36 +1774,36 @@ void S32_alpha_D32_filter_DXDY_SSE2_asm(const SkBitmapProcState& s,
            :[srcAddr] "m" (srcAddr), [colors] "m" (colors), [rb] "m" (rb),
            [count] "m" (count),[alphaScale] "m" (alphaScale),
            [tmp5] "m" (tmp5), [tmp6] "m" (tmp6), [tmp8] "m" (tmp8),
-           [tmp9] "m" (tmp9), [tmpa] "m" (tmpa), [tmpb] "m" (tmpb)
-           :"memory","ecx","esi","edi", "eax"
-           );
-        } // count >= 4
-    }
-    while (count > 0)
-    {
-        data = *xy++;
-        y0 = data >> 14;
-        y1 = data & 0x3FFF;
-        subY = y0 & 0xF;
-        y0 >>= 4;
-
-        data = *xy++;
-        x0 = data >> 14;
-        x1 = data & 0x3FFF;
-        subX = x0 & 0xF;
-        x0 >>= 4;
-
-        row0 = (const SkPMColor*)(srcAddr + y0 * rb);
-        row1 = (const SkPMColor*)(srcAddr + y1 * rb);
-
-        Filter_32_alpha(subX, subY,
+           [tmp9] "m" (tmp9), [tmpa] "m" (tmpa), [tmpb] "m" (tmpb), [vf] "m" (vf),
+           [vmask2] "m" (vmask2), [v256] "m" (v256), [vmask] "m" (vmask)
+           :"memory","ecx","esi","edi", "eax");
+       } // count >= 4
+   }
+   while (count > 0)
+   {
+       data = *xy++;
+       y0 = data >> 14;
+       y1 = data & 0x3FFF;
+       subY = y0 & 0xF;
+       y0 >>= 4;
+
+       data = *xy++;
+       x0 = data >> 14;
+       x1 = data & 0x3FFF;
+       subX = x0 & 0xF;
+       x0 >>= 4;
+
+       row0 = (const SkPMColor*)(srcAddr + y0 * rb);
+       row1 = (const SkPMColor*)(srcAddr + y1 * rb);
+
+       Filter_32_alpha(subX, subY,
                        (row0[x0]),
                        (row0[x1]),
                        (row1[x0]),
                        (row1[x1]),
                        colors,
                        s.fAlphaScale);
-        colors += 1;
-        count --;
-    }
+       colors += 1;
+       count --;
+   }
 }
diff --git a/src/opts/SkBitmapProcState_opts_SSE2.h b/src/opts/SkBitmapProcState_opts_SSE2.h
index ce89034..1c7e006 100644
--- a/src/opts/SkBitmapProcState_opts_SSE2.h
+++ b/src/opts/SkBitmapProcState_opts_SSE2.h
@@ -17,6 +17,16 @@ void S32_opaque_D32_filter_DX_SSE2(const SkBitmapProcState& s,
 void S32_alpha_D32_filter_DX_SSE2(const SkBitmapProcState& s,
                                   const uint32_t* xy,
                                   int count, uint32_t* colors);
+void Color32_SSE2(SkPMColor dst[], const SkPMColor src[], int count,
+                  SkPMColor color);
+void ClampX_ClampY_filter_scale_SSE2(const SkBitmapProcState& s, uint32_t xy[],
+                                     int count, int x, int y);
+void ClampX_ClampY_nofilter_scale_SSE2(const SkBitmapProcState& s,
+                                       uint32_t xy[], int count, int x, int y);
+void ClampX_ClampY_filter_affine_SSE2(const SkBitmapProcState& s,
+                                      uint32_t xy[], int count, int x, int y);
+void ClampX_ClampY_nofilter_affine_SSE2(const SkBitmapProcState& s,
+                                       uint32_t xy[], int count, int x, int y);
 void S32_D16_filter_DX_SSE2(const SkBitmapProcState& s,
                                   const uint32_t* xy,
                                   int count, uint16_t* colors);
@@ -33,18 +43,5 @@ void S32_opaque_D32_filter_DXDY_SSE2_asm(const SkBitmapProcState& s,
 void S32_alpha_D32_filter_DXDY_SSE2_asm(const SkBitmapProcState& s,
                                    const uint32_t* xy,
                                    int count, uint32_t* colors);
-void Color32_SSE2(SkPMColor dst[], const SkPMColor src[], int count,
-                  SkPMColor color);
-void ClampX_ClampY_filter_scale_SSE2(const SkBitmapProcState& s, uint32_t xy[],
-                                     int count, int x, int y);
-void ClampX_ClampY_nofilter_scale_SSE2(const SkBitmapProcState& s,
-                                       uint32_t xy[], int count, int x, int y);
-void ClampX_ClampY_filter_affine_SSE2(const SkBitmapProcState& s,
-                                      uint32_t xy[], int count, int x, int y);
-void ClampX_ClampY_nofilter_affine_SSE2(const SkBitmapProcState& s,
-                                       uint32_t xy[], int count, int x, int y);
-void S32_D16_filter_DX_SSE2(const SkBitmapProcState& s,
-                                  const uint32_t* xy,
-                                  int count, uint16_t* colors);
 
 #endif
diff --git a/src/opts/SkBitmapProcState_opts_SSE2_asm.S b/src/opts/SkBitmapProcState_opts_SSE2_asm.S
index 4102037..6d29db4 100644
--- a/src/opts/SkBitmapProcState_opts_SSE2_asm.S
+++ b/src/opts/SkBitmapProcState_opts_SSE2_asm.S
@@ -318,134 +318,3 @@ nofilter_done:
     pop  %esi
     pop  %ebp
     ret
-
-# extern "C" void S32_Opaque_D32_filter_line_SSSE3_asm(const unsigned int* row0,
-#                                       const unsigned int* row1,
-#                                       SkFixed fx,
-#                                       unsigned int subY,
-#                                       unsigned int* colors,
-#                                       SkFixed dx,
-#                                       int count);
-
-.globl S32_Opaque_D32_filter_line_SSSE3_asm;
-S32_Opaque_D32_filter_line_SSSE3_asm:
-    push %ebp
-    mov  %esp, %ebp
-    push    %esi
-    push    %edi
-    push    %ebx
-    lea    -0xc(%esp),%esp
-
-
-    mov    0x10(%ebp),%eax
-    mov    %eax,%edi
-    shr    $0xc,%edi
-    and    $0xf,%edi
-    movd   %edi,%xmm4
-    pshuflw $0x0,%xmm4,%xmm6 ## (0, 0, 0, 0,x,x,x,x)
-
-    mov    $0x10,%ecx
-    movd   %ecx,%xmm0
-    pshuflw $0x0,%xmm0,%xmm1
-    movdqa %xmm1,%xmm3      ##xmm1 = sixteen
-    psubw  %xmm6,%xmm3      ##(0, 0, 0, 0, 16-x, 16-x, 16-x, 16-x)
-    punpcklqdq %xmm6,%xmm3  ##(x,x,x,x, 16-x,16-x,16-x,16-x)
-
-    ##subY << 8 | 16-subY
-    mov    0x14(%ebp),%ecx
-    mov    %ecx,%edx
-    shl    $0x8,%ecx
-
-    neg    %edx
-    add    $0x10,%edx
-    or     %edx,%ecx
-    movd   %ecx,%xmm0 ## allY = _mm_cvtsi32_si128((subY << 8) | (16 - subY))
-    pshuflw $0x0,%xmm0,%xmm0
-    pshufd $0x0,%xmm0,%xmm0  #xmm0 = allY
-
-    mov    0x8(%ebp),%eax   #eax: row0
-    mov    0xc(%ebp),%edx   #edx: row1
-    mov    0x18(%ebp),%esi    #esi: colors
-
-    mov    0x20(%ebp),%ebx     #ebp: count
-    mov    %ebx, %ecx          #unroll the loop,count = count/2
-    shr    $0x1, %ebx          #unroll the loop,count = count/2
-    and    $1,%ecx             #if count = odd, go odd first and even loop
-
-    jz     .LevenPrepare
-
-        mov    0x1c(%ebp),%ecx   #ecx: dx
-        mov    0x10(%ebp),%ebp
-        mov    %ebp,%edi
-        sar    $0x10,%edi               #fx>>16
-        movdqa %xmm3,%xmm5
-        jmp     .Loddloop
-
-.LevenPrepare:
-    mov    0x1c(%ebp),%ecx   #ecx: dx
-    mov    0x10(%ebp),%ebp
-    mov    %ebp,%edi
-    sar    $0x10,%edi               #fx>>16
-
-.align 16
-.Levenloop:
-    movq   (%eax,%edi,4),%xmm4     #a01a00
-    dec    %ebx                    #ebx = count --
-    movq   (%edx,%edi,4),%xmm2     #a11a10
-    punpcklbw %xmm2,%xmm4          #a01a00 = _mm_unpacklo_epi8(a01a00, a11a10);
-    pmaddubsw %xmm0,%xmm4          #sum = _mm_maddubs_epi16(a01a00, allY);
-    pmullw %xmm3,%xmm4             #sum = _mm_mullo_epi16(sum, negX);
-    add    %ecx,%ebp               #fx = fx+dx
-    pshufd $0xe,%xmm4,%xmm3        #shifted = _mm_shuffle_epi32(sum, 0xE);
-
-    paddw  %xmm3,%xmm4             #sum = _mm_add_epi16(sum, shifted);
-    mov    %ebp,%edi
-
-    psrlw  $0x8,%xmm4              #sum = _mm_srli_epi16(sum, 8)
-    shr    $0xc,%edi               #fx>>12 & 0xF
-    packuswb %xmm3,%xmm4           #sum = _mm_packus_epi16(sum, shifted)
-    and    $0xf,%edi
-    movd   %edi,%xmm5              #allX = _mm_cvtsi32_si128(subX);
-    movd   %xmm4,(%esi)            #*colors = _mm_cvtsi128_si32(sum)
-    add    $0x4,%esi               #colors++
-
-    mov    %ebp,%edi
-    sar    $0x10,%edi               #fx>>16
-.Loddloop:
-    movq   (%eax,%edi,4),%xmm2
-    movq   (%edx,%edi,4),%xmm6
-    punpcklbw %xmm6,%xmm2
-
-    pmaddubsw %xmm0,%xmm2
-    movdqa %xmm1,%xmm6
-    pshuflw $0x0,%xmm5,%xmm7       #allX = _mm_shufflelo_epi16(allX, 0)
-    psubw  %xmm7,%xmm6             #negX = _mm_sub_epi16(sixteen, allX)
-    punpcklqdq %xmm7,%xmm6         #negX = _mm_unpacklo_epi64(negX, allX)
-    add    %ecx,%ebp               #fx = fx + dx
-    pmullw %xmm6,%xmm2             #sum = _mm_mullo_epi16(sum, negX)
-    mov    %ebp,%edi
-    shr    $0xc,%edi               #fx>>12 & 0xF
-
-    and    $0xf,%edi
-    pshufd $0xe,%xmm2,%xmm7
-    paddw  %xmm7,%xmm2
-    psrlw  $0x8,%xmm2
-    movd   %edi,%xmm3
-    mov    %ebp,%edi
-    pshuflw $0x0,%xmm3,%xmm4
-    movdqa %xmm1,%xmm3
-    packuswb %xmm7,%xmm2
-    psubw  %xmm4,%xmm3
-    movd   %xmm2,(%esi)
-    add    $0x4,%esi            #colors = colors + 8
-    sar    $0x10,%edi           #fx >> 16
-    punpcklqdq %xmm4,%xmm3
-    test   %ebx,%ebx
-    jg     .Levenloop
-
-    lea    0xc(%esp),%esp
-    pop    %ebx
-    pop    %edi
-    pop    %esi
-    pop    %ebp
-    ret
diff --git a/src/opts/SkBitmapProcState_opts_SSSE3.cpp b/src/opts/SkBitmapProcState_opts_SSSE3.cpp
index 351eb28..9e91851 100644
--- a/src/opts/SkBitmapProcState_opts_SSSE3.cpp
+++ b/src/opts/SkBitmapProcState_opts_SSSE3.cpp
@@ -9,6 +9,24 @@
 #include "SkBitmapProcState_opts_SSSE3.h"
 #include "SkPaint.h"
 #include "SkUtils.h"
+#include "SkBitmapProcState_filter.h"
+extern "C" void S32_Opaque_D32_filter_line_SSSE3_asm(uint32_t* row0,
+                                  uint32_t* row1,
+                                  SkFixed fx, unsigned subY,
+                                  uint32_t* colors, SkFixed dx,
+                                  int count);
+#define COUNT_NUMS_OF_STAGE(start, end, det)\
+   do { \
+       num = ((end) - (start))/(det)+1;\
+       if (num < rest )        \
+       {                       \
+           runs = num;         \
+           rest = rest - num;  \
+       } else {                \
+           runs = rest;        \
+           rest = 0;           \
+       }                       \
+   } while (0)
 
 // adding anonymous namespace seemed to force gcc to inline directly the
 // instantiation, instead of creating the functions
@@ -723,77 +741,176 @@ void S32_alpha_D32_filter_DXDY_SSSE3(const SkBitmapProcState& s,
     S32_generic_D32_filter_DXDY_SSSE3<true>(s, xy, count, colors);
 
 }
+static void S32_Opaque_D32_filter_line(uint32_t* row0, uint32_t* row1,
+                                  SkFixed fx, unsigned subY,
+                                  uint32_t* colors, SkFixed dx,
+                                  int count) {
+   while (count--) {
+       unsigned subX = (((fx) >> 12) & 0xF);
+       unsigned x0 = (fx) >> 16;
+       Filter_32_opaque(subX, subY, row0[x0], row0[x0+1],
+                                  row1[x0], row1[x0+1], colors);
+       colors++;
+       fx += dx;
+   }
+}
+static SkFixed S32_Opaque_D32_filter_line_rewind(uint32_t* row0,
+                                           uint32_t* row1,
+                                           SkFixed fx, unsigned subY,
+                                           uint32_t* colors, SkFixed dx,
+                                           int count, SkFixed oneX,
+                                           int maxX) {
+   while (count--) {
+       unsigned subX = (((fx) >> 12) & 0xF);
+       int x0 = (fx) >> 16;
+       if (x0 < 0) x0 = x0 + maxX;
+       int x1 = (fx + oneX) >> 16;
+       if (x1 > maxX) x1 = x1 -maxX;
+       Filter_32_opaque(subX, subY, row0[x0], row0[x1],
+                                  row1[x0], row1[x1], colors);
+       colors++;
+       fx += dx;
+   }
+   return fx;
+}
+
 /*
  * sum  = a00(16-y)(16-x) + a10(y)(16-x)
  *      + a01(16-y)(x)    + a11(y)(x)
  *
  */
-extern void S32_Opaque_D32_filter_line_SSSE3(uint32_t* row0, uint32_t* row1,
+void S32_Opaque_D32_filter_line_SSSE3_portable(uint32_t* row0, uint32_t* row1,
                                      SkFixed fx, unsigned subY,
                                      uint32_t* colors, SkFixed dx, int count) {
-    unsigned  subX = (((fx) >> 12) & 0xF);
-
-    unsigned x0 = ((fx) >> 16);
-    // ( 0,  0,  0,  0,  0,  0,  0, 16)
-    __m128i sixteen = _mm_cvtsi32_si128(16);
-
-    // ( 0,  0,  0,  0, 16, 16, 16, 16)
-    sixteen = _mm_shufflelo_epi16(sixteen, 0);
-
-    __m128i allY = _mm_cvtsi32_si128((subY << 8) | (16 - subY));
-
-    // (y, 16-y, y, 16-y,y,16-y,y,16-y)
-    allY = _mm_shufflelo_epi16(allY, 0);
-
-    // (y,16-y, y,16-y,y,16-y,y,16-y,y,16-y,y,16-y,y,16-y,y,16-y)
-    allY = _mm_shuffle_epi32(allY, 0);
-
-    // ( 0,  0,  0,  0,  0,  0,  0,  0)
-    __m128i zero = _mm_setzero_si128();
-
-    __m128i allX = _mm_cvtsi32_si128(subX);
-        // (,,,,x,x,x,x)
-    allX = _mm_shufflelo_epi16(allX, 0);
-    // (,,,,16-x,16-x,16-x,16-x)
-    __m128i negX = _mm_sub_epi16(sixteen, allX);
-    // (x,x,x,x,16-x,16-x,16-x,16-x)
-    negX = _mm_unpacklo_epi64(negX, allX);
-
-    do {
-        __m128i a00 = _mm_cvtsi32_si128(row0[x0]);
-        __m128i a01 = _mm_cvtsi32_si128(row0[x0+1]);
-        __m128i a10 = _mm_cvtsi32_si128(row1[x0]);
-        __m128i a11 = _mm_cvtsi32_si128(row1[x0+1]);
-
-        // (0, 0, a10, a00)
-        __m128i a01a00 = _mm_unpacklo_epi32(a00, a01);
-        // (0, 0, a11, a10)
-        __m128i a11a10 = _mm_unpacklo_epi32(a10, a11);
-
-        // (....A10,A00,R10,R00,G10,G00,B10,B00)
-        a01a00= _mm_unpacklo_epi8(a01a00, a11a10);
-        // [..A00*(16-y)+ A10*y, R00*(16-y)+ R10*y, G00*(16-y)+ G10*y, B00*(16-y)+ B10*y]
-        __m128i sum = _mm_maddubs_epi16(a01a00, allY);
-
-        // [...(G00*(16-y)+ G10*y)(16-x),(B00*(16-y)+ B10*y) * (16-x)]
-        sum = _mm_mullo_epi16(sum, negX);
-        // [...(G01*(16-y)+ G11*y)(x),(B01*(16-y)+ B11*y) * (x)]
-        __m128i shifted = _mm_shuffle_epi32(sum, 0xE);
-        sum = _mm_add_epi16(sum, shifted);
-        sum = _mm_srli_epi16(sum, 8);
-        // Pack lower 4 16 bit values of sum into lower 4 bytes.
-        sum = _mm_packus_epi16(sum, shifted);
-        *colors++ = _mm_cvtsi128_si32(sum);
-
-        fx+= dx;
-        x0 = ((fx) >> 16);
-        subX = (((fx) >> 12) & 0xF);
-        allX = _mm_cvtsi32_si128(subX);
-        // (,,,,x,x,x,x)
-        allX = _mm_shufflelo_epi16(allX, 0);
-        // (,,,,16-x,16-x,16-x,16-x)
-        negX = _mm_sub_epi16(sixteen, allX);
-        // (x,x,x,x,16-x,16-x,16-x,16-x)
-        negX = _mm_unpacklo_epi64(negX, allX);
-    } while (--count > 0);
+   unsigned  subX = (((fx) >> 12) & 0xF);
+
+   unsigned x0 = ((fx) >> 16);
+   // ( 0,  0,  0,  0,  0,  0,  0, 16)
+   __m128i sixteen = _mm_cvtsi32_si128(16);
+
+   // ( 0,  0,  0,  0, 16, 16, 16, 16)
+   sixteen = _mm_shufflelo_epi16(sixteen, 0);
+
+   __m128i allY = _mm_cvtsi32_si128((subY << 8) | (16 - subY));
+
+   // (y, 16-y, y, 16-y,y,16-y,y,16-y)
+   allY = _mm_shufflelo_epi16(allY, 0);
+
+   // (y,16-y, y,16-y,y,16-y,y,16-y,y,16-y,y,16-y,y,16-y,y,16-y)
+   allY = _mm_shuffle_epi32(allY, 0);
+
+   // ( 0,  0,  0,  0,  0,  0,  0,  0)
+   __m128i zero = _mm_setzero_si128();
+
+   __m128i allX = _mm_cvtsi32_si128(subX);
+   // (,,,,x,x,x,x)
+   allX = _mm_shufflelo_epi16(allX, 0);
+   // (,,,,16-x,16-x,16-x,16-x)
+   __m128i negX = _mm_sub_epi16(sixteen, allX);
+   // (x,x,x,x,16-x,16-x,16-x,16-x)
+   negX = _mm_unpacklo_epi64(negX, allX);
+
+   do {
+       __m128i a00 = _mm_cvtsi32_si128(row0[x0]);
+       __m128i a01 = _mm_cvtsi32_si128(row0[x0+1]);
+       __m128i a10 = _mm_cvtsi32_si128(row1[x0]);
+       __m128i a11 = _mm_cvtsi32_si128(row1[x0+1]);
+
+       // (0, 0, a10, a00)
+       __m128i a01a00 = _mm_unpacklo_epi32(a00, a01);
+       // (0, 0, a11, a10)
+       __m128i a11a10 = _mm_unpacklo_epi32(a10, a11);
+
+       // (....A10,A00,R10,R00,G10,G00,B10,B00)
+       a01a00= _mm_unpacklo_epi8(a01a00, a11a10);
+       // [..A00*(16-y)+ A10*y, R00*(16-y)+ R10*y, G00*(16-y)+ G10*y, B00*(16-y)+ B10*y]
+       __m128i sum = _mm_maddubs_epi16(a01a00, allY);
+
+       // [...(G00*(16-y)+ G10*y)(16-x),(B00*(16-y)+ B10*y) * (16-x)]
+       sum = _mm_mullo_epi16(sum, negX);
+       // [...(G01*(16-y)+ G11*y)(x),(B01*(16-y)+ B11*y) * (x)]
+       __m128i shifted = _mm_shuffle_epi32(sum, 0xE);
+       sum = _mm_add_epi16(sum, shifted);
+       sum = _mm_srli_epi16(sum, 8);
+       // Pack lower 4 16 bit values of sum into lower 4 bytes.
+       sum = _mm_packus_epi16(sum, shifted);
+       *colors++ = _mm_cvtsi128_si32(sum);
+
+       fx+= dx;
+       x0 = ((fx) >> 16);
+       subX = (((fx) >> 12) & 0xF);
+       allX = _mm_cvtsi32_si128(subX);
+       // (,,,,x,x,x,x)
+       allX = _mm_shufflelo_epi16(allX, 0);
+       // (,,,,16-x,16-x,16-x,16-x)
+       negX = _mm_sub_epi16(sixteen, allX);
+       // (x,x,x,x,16-x,16-x,16-x,16-x)
+       negX = _mm_unpacklo_epi64(negX, allX);
+   } while (--count > 0);
+}
+
+void Repeat_S32_Opaque_D32_filter_DX_shaderproc_opt(const SkBitmapProcState& s,
+                                            int x, int y, uint32_t* colors,
+                                            int count) {
+   SkASSERT((s.fBitmap->width()) > 1);
+   SkASSERT(((s.fInvSx) > 0) && (s.fInvSx & 0xFFFF));
+   const unsigned maxX = s.fBitmap->width() - 1;
+   const SkFixed oneX = s.fFilterOneX;
+   const SkFixed dx = s.fInvSx;
+   SkFixed fx;
+   uint32_t* row0;
+   uint32_t* row1;
+   unsigned subY;
+   {
+       SkPoint pt;
+       s.fInvProc(s.fInvMatrix, ((float)(x)) + (0.5f),
+                  ((float)(y)) + (0.5f), &pt);
+       SkFixed fy = ((SkFixed)((pt.fY) * (1 << 16))) - (s.fFilterOneY >> 1);
+       const unsigned maxY = s.fBitmap->height() - 1;
+
+       subY =  ((((fy) & 0xFFFF) * ((maxY) + 1) >> 12) & 0xF);
+       int y0 = (((fy) & 0xFFFF) * ((maxY) + 1) >> 16);
+       int y1 = (((fy + s.fFilterOneY) & 0xFFFF) * ((maxY) + 1) >> 16);
+
+       const char* __restrict__ srcAddr = (const char*)s.fBitmap->getPixels();
+       unsigned rb = s.fBitmap->rowBytes();
+       row0 = (uint32_t*)(srcAddr + y0 * rb);
+       row1 = (uint32_t*)(srcAddr + y1 * rb);
+
+       fx = SkScalarToFixed(pt.fX) - (oneX >> 1);
+       SkFixed fmax = (maxX << 16);
+       SkFixed foneX = oneX *(maxX+1);
+       int num = 0;
+       int runs = 0;
+       int rest = count;
+       SkFixed ffx = (fx & 0xFFFF )* ( maxX+1 );
+       SkFixed fdx = (dx & 0xFFFF) * ( maxX+1 );
+       SkFixed ffx1 = ffx + foneX;
+       while (rest > 0)
+       {
+           //normal case;
+           if (ffx >= 0 && ffx1 < fmax)
+           {
+               COUNT_NUMS_OF_STAGE(ffx1, fmax, fdx);
+               S32_Opaque_D32_filter_line_SSSE3_asm(row0, row1, ffx, subY,
+                                               colors, fdx, runs);
+               ffx = ffx + fdx * runs;
+               colors = colors + runs;
+               ffx1 = ffx + foneX;
+           }
+           // rare case
+           if (rest > 0 && ffx < fmax && ffx1 >= fmax) {
+               COUNT_NUMS_OF_STAGE(ffx, fmax, fdx);
+               ffx = S32_Opaque_D32_filter_line_rewind(row0, row1, ffx, subY,
+                                               colors, fdx, runs, foneX, maxX);
+               colors = colors + runs;
+               ffx1 = ffx + foneX;
+           }
+           if (ffx >= fmax) {
+               // rewind ffx;
+               ffx = ffx - fmax;
+               ffx1 = ffx + foneX;
+           }
+       }
+   }
 }
diff --git a/src/opts/SkBitmapProcState_opts_SSSE3.h b/src/opts/SkBitmapProcState_opts_SSSE3.h
index 9fd074a..48eb6ef 100644
--- a/src/opts/SkBitmapProcState_opts_SSSE3.h
+++ b/src/opts/SkBitmapProcState_opts_SSSE3.h
@@ -22,5 +22,8 @@ void S32_opaque_D32_filter_DXDY_SSSE3(const SkBitmapProcState& s,
 void S32_alpha_D32_filter_DXDY_SSSE3(const SkBitmapProcState& s,
                                    const uint32_t* xy,
                                    int count, uint32_t* colors);
+void Repeat_S32_Opaque_D32_filter_DX_shaderproc_opt(const SkBitmapProcState& s,
+                                            int x, int y, uint32_t* colors,
+                                            int count);
 
 #endif
diff --git a/src/opts/SkBitmapProcState_opts_SSSE3_asm.S b/src/opts/SkBitmapProcState_opts_SSSE3_asm.S
new file mode 100644
index 0000000..e9ed219
--- /dev/null
+++ b/src/opts/SkBitmapProcState_opts_SSSE3_asm.S
@@ -0,0 +1,130 @@
+# extern "C" void S32_Opaque_D32_filter_line_SSSE3_asm(const unsigned int* row0,
+#                                       const unsigned int* row1,
+#                                       SkFixed fx,
+#                                       unsigned int subY,
+#                                       unsigned int* colors,
+#                                       SkFixed dx,
+#                                       int count);
+
+.globl S32_Opaque_D32_filter_line_SSSE3_asm;
+S32_Opaque_D32_filter_line_SSSE3_asm:
+    push %ebp
+    mov  %esp, %ebp
+    push    %esi
+    push    %edi
+    push    %ebx
+    lea    -0xc(%esp),%esp
+
+
+    mov    0x10(%ebp),%eax
+    mov    %eax,%edi
+    shr    $0xc,%edi
+    and    $0xf,%edi
+    movd   %edi,%xmm4
+    pshuflw $0x0,%xmm4,%xmm6 ## (0, 0, 0, 0,x,x,x,x)
+
+    mov    $0x10,%ecx
+    movd   %ecx,%xmm0
+    pshuflw $0x0,%xmm0,%xmm1
+    movdqa %xmm1,%xmm3      ##xmm1 = sixteen
+    psubw  %xmm6,%xmm3      ##(0, 0, 0, 0, 16-x, 16-x, 16-x, 16-x)
+    punpcklqdq %xmm6,%xmm3  ##(x,x,x,x, 16-x,16-x,16-x,16-x)
+
+    ##subY << 8 | 16-subY
+    mov    0x14(%ebp),%ecx
+    mov    %ecx,%edx
+    shl    $0x8,%ecx
+
+    neg    %edx
+    add    $0x10,%edx
+    or     %edx,%ecx
+    movd   %ecx,%xmm0 ## allY = _mm_cvtsi32_si128((subY << 8) | (16 - subY))
+    pshuflw $0x0,%xmm0,%xmm0
+    pshufd $0x0,%xmm0,%xmm0  #xmm0 = allY
+
+    mov    0x8(%ebp),%eax   #eax: row0
+    mov    0xc(%ebp),%edx   #edx: row1
+    mov    0x18(%ebp),%esi    #esi: colors
+
+    mov    0x20(%ebp),%ebx     #ebp: count
+    mov    %ebx, %ecx          #unroll the loop,count = count/2
+    shr    $0x1, %ebx          #unroll the loop,count = count/2
+    and    $1,%ecx             #if count = odd, go odd first and even loop
+
+    jz     .LevenPrepare
+
+        mov    0x1c(%ebp),%ecx   #ecx: dx
+        mov    0x10(%ebp),%ebp
+        mov    %ebp,%edi
+        sar    $0x10,%edi               #fx>>16
+        movdqa %xmm3,%xmm5
+        jmp     .Loddloop
+
+.LevenPrepare:
+    mov    0x1c(%ebp),%ecx   #ecx: dx
+    mov    0x10(%ebp),%ebp
+    mov    %ebp,%edi
+    sar    $0x10,%edi               #fx>>16
+
+.align 16
+.Levenloop:
+    movq   (%eax,%edi,4),%xmm4     #a01a00
+    dec    %ebx                    #ebx = count --
+    movq   (%edx,%edi,4),%xmm2     #a11a10
+    punpcklbw %xmm2,%xmm4          #a01a00 = _mm_unpacklo_epi8(a01a00, a11a10);
+    pmaddubsw %xmm0,%xmm4          #sum = _mm_maddubs_epi16(a01a00, allY);
+    pmullw %xmm3,%xmm4             #sum = _mm_mullo_epi16(sum, negX);
+    add    %ecx,%ebp               #fx = fx+dx
+    pshufd $0xe,%xmm4,%xmm3        #shifted = _mm_shuffle_epi32(sum, 0xE);
+
+    paddw  %xmm3,%xmm4             #sum = _mm_add_epi16(sum, shifted);
+    mov    %ebp,%edi
+
+    psrlw  $0x8,%xmm4              #sum = _mm_srli_epi16(sum, 8)
+    shr    $0xc,%edi               #fx>>12 & 0xF
+    packuswb %xmm3,%xmm4           #sum = _mm_packus_epi16(sum, shifted)
+    and    $0xf,%edi
+    movd   %edi,%xmm5              #allX = _mm_cvtsi32_si128(subX);
+    movd   %xmm4,(%esi)            #*colors = _mm_cvtsi128_si32(sum)
+    add    $0x4,%esi               #colors++
+
+    mov    %ebp,%edi
+    sar    $0x10,%edi               #fx>>16
+.Loddloop:
+    movq   (%eax,%edi,4),%xmm2
+    movq   (%edx,%edi,4),%xmm6
+    punpcklbw %xmm6,%xmm2
+
+    pmaddubsw %xmm0,%xmm2
+    movdqa %xmm1,%xmm6
+    pshuflw $0x0,%xmm5,%xmm7       #allX = _mm_shufflelo_epi16(allX, 0)
+    psubw  %xmm7,%xmm6             #negX = _mm_sub_epi16(sixteen, allX)
+    punpcklqdq %xmm7,%xmm6         #negX = _mm_unpacklo_epi64(negX, allX)
+    add    %ecx,%ebp               #fx = fx + dx
+    pmullw %xmm6,%xmm2             #sum = _mm_mullo_epi16(sum, negX)
+    mov    %ebp,%edi
+    shr    $0xc,%edi               #fx>>12 & 0xF
+
+    and    $0xf,%edi
+    pshufd $0xe,%xmm2,%xmm7
+    paddw  %xmm7,%xmm2
+    psrlw  $0x8,%xmm2
+    movd   %edi,%xmm3
+    mov    %ebp,%edi
+    pshuflw $0x0,%xmm3,%xmm4
+    movdqa %xmm1,%xmm3
+    packuswb %xmm7,%xmm2
+    psubw  %xmm4,%xmm3
+    movd   %xmm2,(%esi)
+    add    $0x4,%esi            #colors = colors + 8
+    sar    $0x10,%edi           #fx >> 16
+    punpcklqdq %xmm4,%xmm3
+    test   %ebx,%ebx
+    jg     .Levenloop
+
+    lea    0xc(%esp),%esp
+    pop    %ebx
+    pop    %edi
+    pop    %esi
+    pop    %ebp
+    ret
diff --git a/src/opts/SkBlitRow_opts_SSE2.h b/src/opts/SkBlitRow_opts_SSE2.h
index 628fbae..f61f98f 100644
--- a/src/opts/SkBlitRow_opts_SSE2.h
+++ b/src/opts/SkBlitRow_opts_SSE2.h
@@ -30,25 +30,26 @@ void SkBlitLCD16Row_SSE2(SkPMColor dst[], const uint16_t src[],
                          SkColor color, int width, SkPMColor);
 void SkBlitLCD16OpaqueRow_SSE2(SkPMColor dst[], const uint16_t src[],
                                SkColor color, int width, SkPMColor opaqueDst);
-void S32A_D565_Blend_SSE2(uint16_t* SK_RESTRICT dst, const SkPMColor* SK_RESTRICT src,
-        int count, U8CPU alpha, int /*x*/, int /*y*/);
+void S32A_D565_Blend_SSE2(uint16_t* SK_RESTRICT dst,
+        const SkPMColor* SK_RESTRICT src, int count, U8CPU alpha, int /*x*/, int /*y*/);
 
-void S32A_D565_Opaque_SSE2(uint16_t* SK_RESTRICT dst, const SkPMColor* SK_RESTRICT src,
-        int count, U8CPU alpha, int /*x*/, int /*y*/);
+void S32A_D565_Opaque_SSE2(uint16_t* SK_RESTRICT dst,
+        const SkPMColor* SK_RESTRICT src, int count, U8CPU alpha, int /*x*/, int /*y*/);
 
 void S32A_D565_Opaque_Dither_SSE2(uint16_t* SK_RESTRICT dst,
         const SkPMColor* SK_RESTRICT src, int count, U8CPU alpha, int x, int y);
 
-void S32_D565_Opaque_SSE2(uint16_t* __restrict__ dst, const SkPMColor* __restrict__ src,
-        int count, U8CPU alpha, int x, int y);
+void S32_D565_Opaque_SSE2(uint16_t* SK_RESTRICT dst, const SkPMColor* SK_RESTRICT src,int count,
+        U8CPU alpha, int x, int y);
 
-void S32_D565_Blend_SSE2(uint16_t* __restrict__ dst, const SkPMColor* __restrict__ src,
-        int count, U8CPU alpha, int x, int y);
+void S32_D565_Blend_SSE2(uint16_t* SK_RESTRICT dst, const SkPMColor* SK_RESTRICT src,int count,
+        U8CPU alpha, int x, int y);
 
-void S32_D565_Opaque_Dither_SSE2(uint16_t* __restrict__ dst,
-        const SkPMColor* __restrict__ src,int count, U8CPU alpha, int x, int y);
+void S32_D565_Opaque_Dither_SSE2(uint16_t* SK_RESTRICT dst, const SkPMColor* SK_RESTRICT src,
+        int count, U8CPU alpha, int x, int y);
 
-void S32_D565_Blend_Dither_SSE2(uint16_t* __restrict__ dst,
-        const SkPMColor* __restrict__ src, int count, U8CPU alpha, int x, int y);
+void S32_D565_Blend_Dither_SSE2(uint16_t* SK_RESTRICT dst, const SkPMColor* SK_RESTRICT src,
+        int count,
+        U8CPU alpha, int x, int y);
 
 #endif
diff --git a/src/opts/opts_check_x86.cpp b/src/opts/opts_check_x86.cpp
index 8acbe1f..463fc55 100644
--- a/src/opts/opts_check_x86.cpp
+++ b/src/opts/opts_check_x86.cpp
@@ -18,18 +18,13 @@
 #include "SkUtils.h"
 #include "SkMorphology_opts.h"
 #include "SkMorphology_opts_SSE2.h"
-
+#include "SkShader.h"
 #include "SkRTConf.h"
 
 #if defined(_MSC_VER) && defined(_WIN64)
 #include <intrin.h>
 #endif
 
-#include "SkShader.h"
-extern void Repeate_S32_Opaque_D32_filter_DX_shaderproc_opt(
-                                       const SkBitmapProcState& s,
-                                       int x, int y, uint32_t* colors,
-                                       int count);
 /* This file must *not* be compiled with -msse or -msse2, otherwise
    gcc may generate sse2 even for scalar ops (and thus give an invalid
    instruction on Pentium3 on the code below).  Only files named *_SSE2.cpp
@@ -129,7 +124,7 @@ void SkBitmapProcState::platformProcs() {
             const unsigned max = fBitmap->width();
             // SSSE3 opted only if more than 4 pixels, dx=non-zero
             if ((fInvSx > 0) && repeatXY && (max > 4) && ((fInvSx & 0xFFFF) != 0)) {
-                fShaderProc32 = Repeate_S32_Opaque_D32_filter_DX_shaderproc_opt;    // Not 64-bit compatible
+                fShaderProc32 = Repeat_S32_Opaque_D32_filter_DX_shaderproc_opt;    // Not 64-bit compatible
             }
 #endif
         } else if (SSELevel >= SK_CPU_SSE_LEVEL_SSE2) {
-- 
2.7.4

